{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd9bIxh6DK3w"
      },
      "source": [
        "%%capture\n",
        "!pip install vaderSentiment\n",
        "!pip install transformers\n",
        "!pip install gdown"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnXama3A4ZLh"
      },
      "source": [
        "%%capture\n",
        "import json\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from termcolor import colored\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from statistics import mode\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import zipfile\n",
        "import gdown\n",
        "\n",
        "from transformers import DistilBertForSequenceClassification,DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, TensorDataset,DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from sklearn import metrics\n",
        "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn\n",
        "\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWPmzYRKGvKR",
        "outputId": "30a23686-a7e3-4971-9939-db481db52c6b"
      },
      "source": [
        "# set runtime type on GPU (!), otherwise some code will run really slow\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print('Device available:', device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4eDwDV_V5o"
      },
      "source": [
        "# *A Sentiment Analysis of Spotify Podcasts*\r\n",
        "\r\n",
        "#### NOTE: open this notebook in Google Colab, in order to have access to GPU power\r\n",
        "\r\n",
        "#### NOTE: link to Github repo of this project: [https://github.com/bartvanvulpen/podcastDA](https://github.com/bartvanvulpen/podcastDA)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-HlD2Y6kvfL"
      },
      "source": [
        "\\begin{array}{c|c}\r\n",
        "\\text{Student Name}&\\text{Student ID}\\\\\\hline\r\n",
        "\\text{Bart van Vulpen}&11865210\\\\\r\n",
        "\\text{Juno Prent}&11915307\\\\\r\n",
        "\\text{Joris Hijstek}&11876980\\\\\r\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxcGHeOF_kwZ"
      },
      "source": [
        "## Contents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCUwI6ja_yr5"
      },
      "source": [
        "## 1 Introduction\n",
        "A podcast is an audio file that contains a monologue, or a dialogue of one or more participants, which can be easily downloaded or streamed and listened to. The term podcast was first coined by the columnist and journalist Ben Hammersley in February 2004 as a way to combine the terms *'i-Pod'* and *'broadcasting'*. \n",
        "In 2005, the American company *Apple* released a new version of iTunes which provided a centralized platform for podcasts to be uploaded and downloaded from.\n",
        "\n",
        "\n",
        "It is a traditional task in A.I. to predict the general tone of a sentence or sequence. For example, a company owner might attempt to filter positive reviews from negative reviews, but this can be taxing to do by hand. Thus, the owner could decide to have the reviews analyzed by an automated agent. The conventional name for an agent performing such a task is sentiment analysis.\n",
        "\n",
        "\n",
        "Podcasts are interesting because they come in various shapes and sizes. Some are serious political talkshows while others are completely based on fiction. An interesting task would therefore be to detect the general mood throughout a podcast in order to learn more about the general composition of its contents.\n",
        "\n",
        "Therefore, the main research question will be as follows: *What sentiment patterns can be found in podcasts episodes?* The question is split up into two subquestions: *What sentiment patterns can be found within podcast dialogues?* and *What sentiment patterns can be found in podcast dialogues in general?*.\n",
        "\n",
        "Since sentiment analysis and sentiment prediction in podcasts has not been widely researched yet, several methods for this task will be explored first. Methods based on lexicons, unsupervised machine-learning and the state-of-the-art Transformer model will be examined to find the best performing architecture for predicting sentiment in podcast dialogues. Finally, the best performing method will be used to mine sentiment patterns within podcast dialogues and in podcast dialogues in general. The sentiment prediction task is described in Section 2. The background and related work of this project is described in Section 3. The properties of the dataset that is being used are assessed in Section 4. The several methods that will be examined are described in Section 5. Section 6 assesses the results, followed by the discussion, conclusion and future work in Section 7 and 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_VtzYR7YcT5"
      },
      "source": [
        "## 2 The Sentiment Prediction Task\n",
        "\n",
        "A dialogue constist of mutiple utterances of each speaker participating in that dialogue. Each utterance in the dialogue has a certain degree of sentiment. These so called sentiment scores can then be used for sentiment analysis and sentiment pattern mining within and between dialogues.\n",
        "Using the sentiment prediction task, these sentiment scores can be predicted for a utterance text. The task is relatively simple and set up below. \\\n",
        "\\\n",
        "Suppose $\\mathbf{x}$ is a dialogue containing $N$ utterances:\n",
        "\n",
        "\\\n",
        "\\begin{equation}\n",
        "   \\mathbf{x}  = \\{x_1, x_2, x_3, ..., x_N \\}\n",
        "\\end{equation}\n",
        "\n",
        "\\\n",
        "In the task, the sentiment score $s_i$ of each utterance $x_i$ is predicted using a given model M.\n",
        "\\\n",
        "\\\n",
        "\\begin{equation}\n",
        "    s_i = \\mathbf{M}(x)\n",
        "\\end{equation}\n",
        "\\\n",
        "The sentiment score $s_i$ can then be classified in a label $y_i$, for example 'positive' or 'negative', based on the followinng condition:\n",
        "\n",
        "\\\n",
        "\\begin{equation}\n",
        "    y_i = \n",
        "\\begin{cases}\n",
        "    negative,& \\text{if } s_i\\lt 0\\\\\n",
        "    positive,              & \\text{otherwise}\n",
        "\\end{cases}\\\\\n",
        "\\end{equation}\n",
        "\\\n",
        "where $\\mathbf{y}$ is the vector containing de sentiment labels for the dialogue $\\mathbf{x}$.\n",
        "\\\n",
        "\\\n",
        "\\begin{equation}\n",
        "   \\mathbf{y}  = \\{y_1, y_2, y_3, ..., y_N \\}\n",
        "\\end{equation}\n",
        "\\\n",
        "Label vector $\\mathbf{y}$ can be used to get the sentiment of the total dialogue or can be used for deeper sentiment analysis, which can be seen in Section 5.5 and Section 6.2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvZ_PGC03iNg"
      },
      "source": [
        "## 3 Related work\n",
        "\n",
        "As mentioned before, there is no previous work which analyzed the sentiment in podcasts dialogues. However, in previous work, several methods for analyzing and predicting the sentiment in other kinds of texts have been developed over the years. For example an context-based classification method on reviews was developed by [(Turney, 2002)](https://www.aclweb.org/anthology/P02-1053.pdf). Turney determined sentiment scores, there referring to them as semantic orientations of phrases, which is any two-word pair with a specific predefined combination of part-of-speech tags (i.e. ‘adverb-adjective’ or ‘adjective-singular noun’) within online reviews by looking at the amount of times the words ‘excellent’ and ‘poor’ are in the vicinity of those phrases. Sentiment can also be predicted by using a lexicon of words and their associated sentiment score. Usually these scores lie between -10 and +10, where -10 is extremely negative and +10 is extremely positive. Using such a lexicon, the sentiment prediction task is made unsupervised as well. [(Taboada et al., 2011)](https://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00049) have shown that such lexicon-based approaches are reliable. \n",
        "They developed The Semantic Orientation CALculator (SO-CAL) that was  consistent across several domains and on unseen data.\n",
        "More statistical aproaches have been developer over the years as well. More statistical aproaches have been developer over the years as well. [(Dey et al., 2016)](https://arxiv.org/pdf/1610.09982.pdf) applied the sentiment prediction task on movie and hotel reviews using two supervised machine learning algorithms Naive Bayes' and K-Nearest Neighbour and compared both algorithm's performances. More complex machine-learning approaches are seen in the use of neural networks. [(Kumar et al., 2019)](https://arxiv.org/pdf/1911.12569.pdf) developed a method for sentiment prediction based on a attention-based Bi-directional LSTM architecture and a distributional Thesaurarus for external knowledge. This method outperformed the state-of-the-art systems on the SemEval 2016 and the Stance Sentiment Emotion Corpus on F-score. Besides LSTM networks,  Convolutional Neural Networks (CNNs) can also be used for the task, as [(Kim, 2014)](https://arxiv.org/pdf/1408.5882.pdf) showed by training a simple CNN on several tasks, including sentiment prediction on customer reviews, which showed state-of-the-art performance as well.\n",
        "\n",
        "Nowadays, state-of-the-art pretrained models are can be finetuned for the sentiment prediction task as well. A good example is BERT (Bidirectional Encoder Representations from Transformers), a Transformer-based [(Vaswani et al., 2017)](https://arxiv.org/pdf/1706.03762.pdf) non-autoregressive language generation model that is very good at predicting the next word in a sequence. BERT is pre-trained on a large corpus of unlabelled text including more than 3,300 millionn words. The model that can be finetuned for several tasks like text summarization and machine translation, but also sentiment prediction. There exists even bigger and more complex models for sentiment prediction that are the current state-of-the-art for this task, like  SMART-RoBERTa Large [(Jiang et al., 2021)](https://arxiv.org/pdf/1911.03437v4.pdf), NB-weighted-BON + dv-cosine [(Thongtan & Phienthrakul, 2019)](https://www.aclweb.org/anthology/P19-2057.pdf) and XLNET [(Yang et al., 2020)](https://arxiv.org/pdf/1906.08237v2.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL7boZQAAo4k"
      },
      "source": [
        "## 4 Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Uvm7mY322y"
      },
      "source": [
        "### 4.1 Spotify Podcast Dataset\n",
        "For analyzing the sentiment within and between podcasts, the Spotify Podcast Dataset \n",
        "[(Clifton et al., 2020)](https://arxiv.org/pdf/2004.04270.pdf) was used. This dataset contains over 100,000 randomly sampled podcast episodes. Each episode has an audio file containing the podcast itself. Also, a transcript was made for each episode using Google's Speech-To-Text model, with a word error rate of 18.1%. Each transcript also contains speaker tags that indicate the speaker who is actually talking. Finally, some metadata was provided containing information about the podcast itself (e.g. language and name). \n",
        "In total, the dataset contains more than 2TB of audio files and more than 100GB of transcript files in JSON format. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8pvzUNk36SF"
      },
      "source": [
        "### 4.2 Data Preprocessing\n",
        "In this project, only the transcripts were used. Due to lack of computational resources, a subset containing more than 40GB of transcripts was taken. Each JSON file containing the transcript of one episode was processed into a Pandas Dataframe containing each utterance in the dialogue with the corresponding speaker tag. Also, an empty sentiment column called *sentiment_score* was added to the dataframe. Below an example of the data structure is shown.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZG-wbv1lQNzb",
        "outputId": "af66f97d-615b-41eb-9e39-d0fcd8e2b526"
      },
      "source": [
        "urllib.request.urlretrieve('https://drive.google.com/uc?id=1GDX2SxEma1ysjWMqqyQugUFXAYdmut7N&export=download', 'dialogue_example.csv')\n",
        "# load binary validation dataset\n",
        "example_df = pd.read_csv('dialogue_example.csv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "example_df.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker_tag</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>The subconscious mind creates the personality....</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Hi everyone. This is the Tuda and you are in s...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Very well actually is enjoying your London. It...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Thank you so much for coming. I'm looking forw...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Yes, definitely. The interesting thing is that...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   speaker_tag  ... sentiment_score\n",
              "0            3  ...             NaN\n",
              "1            1  ...             NaN\n",
              "2            3  ...             NaN\n",
              "3            1  ...             NaN\n",
              "4            3  ...             NaN\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdwHtAtmQTNz"
      },
      "source": [
        "Each DataFrame was exported to a .CSV file. Dialogues with less than five utterances were filtered out. Using the metadata non-English episodes were filtered out as well. This finally resulted in a dataset of 37,610 dialogues, containing 3,014,600 utterances in total. This dataset was split up into three subsets, so each method had it's own dataset to work with.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc8gfGH_4CaF"
      },
      "source": [
        "\n",
        "### 4.3 Labeling Data\n",
        "In order to evaluate each examined method, it was necessary to have a small labeled dataset. Thus, the sentiment of each utterance in several podcast dialogue transcripts were labeled as either negative (0) or positive (1). Since the utterances were automatically generated with a word error rate of 18.1% and dialogue utterances can get really long in podcasts, we decided to not take *neutral* sentiment into account. Taking the neutral label into account as well would make the sentiment prediction task much more difficult and less accurate.\n",
        "\n",
        "In total, 4304 utterances in 54 podcast dialogues were labeled. From these labeled dialogues, a training and validation set was generated by taking a random sample of their utterances.The validation set was used for evaluation of all methods but the Neighbourhood-based Method, as that requires the context of an utterance to score it. There, entire labeled transcripts were randomly picked to train and validate with. The training set was used for the DistilBert sentiment classifier only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYrVg9CNAHGA"
      },
      "source": [
        "## 5 Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI7dOZ4_AtW3"
      },
      "source": [
        "### 5.1 Lexicon-based Sentiment Prediction\n",
        "\n",
        "The first method that was examined made us of lexicons to predict the sentiment of dialogue utterances. In this relatively simple method, two approaches were examined, the first by using SentiWordNet 3.0 \n",
        "[(Baccianella et al., 2010)](http://www.lrec-conf.org/proceedings/lrec2010/pdf/769_Paper.pdf) and the other by using a rule- and lexicon-based sentiment analyzer called VADER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJsXfC23Dp1J"
      },
      "source": [
        "#### 5.1.1 SentiWordNet\n",
        "In this approach, the lexical resource called SentiWordNet was used. This lexicon is made for opinion mining and sentiment analysis and is based on the famous WordNet [(George A. Miller (1995)](https://www.aclweb.org/anthology/H94-1111.pdf). For each synset (a set of synonyms that share a common meaning) in WordNet, a positivity score, negativity score and objectivity score is assigned by SentiWordNet, so it simply is a large corpus containing POS-tagged English words along with their sentiment scores. \n",
        "The lexicon is built on a combination of a quantitive analysis of the glosses associated to synsets in WordNet and a machine learning-based synset classification using the resulting vectoral term representations of the synset glosses [(Esuli & Sebastiani, 2006)](http://nmis.isti.cnr.it/sebastiani/Publications/LREC06.pdf).\n",
        "\n",
        "For predicting the sentiments in a podcast dialogue, each utterance was first tokenized into tokens (or words). Subsequently, the POS-tags for each token were obtained using NLTK's POS tagger. Then, each token was lemmatized and the synset for that token was obtained using its lemma and POS-tag. Thereafter, he sentiment of each token was calculated using the  formula below, where S corresponds items in the token's synset, N to the number of items in the synset and $p\\_score$ and $n\\_score$ to the positivity score and negativity score respectively.\n",
        "\\\n",
        "\\\n",
        "\\begin{equation}\n",
        "  \\text{sentiment score} = \\frac{1}{N}\\sum_{s \\in S}^{N}s_{p\\_score} - s_{n\\_score}\n",
        "\\end{equation} \\\\\n",
        "\n",
        "Finally, in order to calculate the total sentiment of the utterance, the average score of all tokens was taken. The total sentiment was classified as $0$ (negative) or $1$ (positive) using the condition in described in Section 2.\n",
        "\n",
        "In the cell below the Python function for predicting the sentiment label of a podcast dialogue utterance is shown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "852xFBsVA9tQ"
      },
      "source": [
        "def SentiWordNet_sentiment(utterance):\n",
        "    \"\"\"\n",
        "    Returns the sentiment label (0 or 1) for a podcast utterance with tagged tokens \n",
        "    using SentiWordNet\n",
        "    \"\"\"\n",
        "    # tokenize utterance\n",
        "    lemmatizer = nltk.WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(utterance)\n",
        "    \n",
        "    # POS tag utterance\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    \n",
        "    # assign sentiment score using SentiWordNet, including synonyms\n",
        "    tokens_sentiment_scores = []\n",
        "    for token in tagged_tokens:\n",
        "        tag = ''\n",
        "        lemma = lemmatizer.lemmatize(token[0])\n",
        "        if token[1].startswith('N'):\n",
        "            tag = 'n'\n",
        "        elif token[1].startswith('J'):\n",
        "            tag = 'a'\n",
        "        elif token[1].startswith('V'):\n",
        "            tag = 'v'\n",
        "        elif token[1].startswith('R'):\n",
        "            tag = 'r'\n",
        "        if tag != '':\n",
        "            # also get sentiments for synonyms\n",
        "            synonyms = list(swn.senti_synsets(lemma, tag)) \n",
        "            token_sentiment = 0\n",
        "            if len(synonyms) > 0:\n",
        "                for synonym in synonyms:\n",
        "                    token_sentiment += synonym.pos_score() - synonym.neg_score()\n",
        "                tokens_sentiment_scores.append(token_sentiment/len(synonyms))      \n",
        "   \n",
        "    if tokens_sentiment_scores != []:\n",
        "        sentiment_score = sum(tokens_sentiment_scores)/len(tokens_sentiment_scores) \n",
        "\n",
        "        if sentiment_score >= 0:\n",
        "            return 1\n",
        "        elif sentiment_score < 0:\n",
        "            return 0\n",
        "    else:   \n",
        "        return 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCtkWGX_Dilu"
      },
      "source": [
        "#### 5.1.2 VADER Sentiment\n",
        "VADER stands for **V**alence **A**ware **D**ictionary and s**E**ntiment **R**easoner. It is a lexicon and rule-based tool for sentiment-analysis, especially for social media texts [(Hutto & Gilbert, 2014)](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8109/8122/). Vader is based on quantitative and qualitative methods. They first labeled a large lexicon of words with their corresponding sentiment. Subsequently, they combined this lexicon with five rules that represent syntactical and grammatical conventions for expressing sentiment. This makes VADER intelligent enough to understand that “did not love”  is negative and while “love\" is a word with high positive sentiment. VADER is also able to understand  capitalisation and punctuation. For example, ‘GREAT’ and ‘amazing!’ have a higher positive sentiment word than ‘great’ and ‘amazing’.\n",
        "\n",
        "In this approach, the compound (positive, negative and neutral combined) VADER polarity score is used to calculate the sentiment score of an utterance. Following the same condition as the SentiWordNet approach this score is then transformed into a sentiment label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEehHjnXD_Ce"
      },
      "source": [
        "def VADER_sentiment(utterance):\n",
        "    \"\"\"\n",
        "    Returns the VADER-based sentiment label (0 or 1) of a dialogue utterance \n",
        "    using the compound sentiment score.\n",
        "    \"\"\"\n",
        "    analyser = SentimentIntensityAnalyzer()\n",
        "    score = analyser.polarity_scores(utterance)['compound']   \n",
        "    if score >= 0:\n",
        "        return 1\n",
        "    elif score < 0:\n",
        "        return 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-HzM_sRAuZ4"
      },
      "source": [
        "### 5.2 Neighbourhood-based Method\n",
        "\n",
        "The second method was based on the previously mentioned works of [Turney  (2002)](https://www.aclweb.org/anthology/P02-1053.pdf), in which the sentiment scores of online reviews are calculated by looking at the neighbouring words of certain phrases within those reviews. For lack of a better term, this method will be referred to as Neighbourhood-based Method throughout this paper.  For each of those phrases, the amount of occurrences of the words ‘excellent’ and ‘poor’ in the previous and next 10 words are counted, which is derived from the way the AltaVista seach engine’s NEAR operator works. The final semantic orientation of a phrase is then defined as: \n",
        "\n",
        "\\begin{equation}\n",
        "SO = \\log(\\frac{hits(\\text{phrase NEAR 'excellent'})hits(\\text{'poor'})}{hits(\\text{phrase NEAR} 'poor')hits(\\text{'excellent'})})\n",
        "\\end{equation} \\\\\n",
        "\n",
        "To determine whether any two-word pair was a phrase, the following function was used:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laFOUr7oa0-A"
      },
      "source": [
        "# Determines whether two words are considered a phrase according to 'Thumbs Up or Thumbs Down? \n",
        "# Semantic Orientation Applied to Unsupervised Classification of Reviews' by Peter D. Turney, 2002.\n",
        "\n",
        "def is_phrase(word_index, words):\n",
        "    first_tag = nltk.pos_tag([words[word_index]])[0][1]\n",
        "    second_tag = nltk.pos_tag([words[word_index + 1]])[0][1]\n",
        "    # Considers the tag of the word after the potential phrase, if there is one.\n",
        "    try:\n",
        "        third_tag = nltk.pos_tag([words[word_index + 2]])[0][1]\n",
        "    except IndexError:\n",
        "        pass\n",
        "    \n",
        "    if first_tag == 'JJ':\n",
        "        if second_tag in ['NN', 'NNS']:\n",
        "            return True\n",
        "        elif second_tag == 'JJ':\n",
        "            try:\n",
        "                if third_tag not in ['NN', 'NNS']:\n",
        "                    return True\n",
        "            except NameError:\n",
        "                return True\n",
        "    elif first_tag in ['RB', 'RBR', 'RBS']:\n",
        "        if second_tag == 'JJ':\n",
        "            try:\n",
        "                if third_tag not in ['NN', 'NNS']:\n",
        "                    return True\n",
        "            except NameError:\n",
        "                return True\n",
        "        elif second_tag in ['VB', 'VBD', 'VBN', 'VBG']:\n",
        "            return True\n",
        "    elif first_tag in ['NN', 'NNS']:\n",
        "        if second_tag == 'JJ':\n",
        "            try:\n",
        "                if third_tag not in ['NN', 'NNS']:\n",
        "                    return True\n",
        "            except NameError:\n",
        "                return True\n",
        "    # If no correct combination is found, the word pair is not a phrase\n",
        "    return False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzi05F-Oa13y"
      },
      "source": [
        "Applying a method for sentiment analysis that was created for online reviews and applying it to podcast transcripts (or any written dialogue for that matter) quickly presented several needs for alterations. Firstly, the range 10 previous and next words was too low. This value, from now on referred to as the NEAR value, was always at least 50 during the evaluation. Secondly, the words ‘excellent’ and ‘poor’ proved to be far too scarcely used to get accurate scores. To better capture the broad range of vocabulary that is used by different people across many podcasts, two lists – one with positive words, one with negative ones – were used instead. These were each comprised of the most frequent adjectives across the dataset and some more frequent sentiment indicating words such as ‘yes’ and ‘no’. This lead to the following lists:\n",
        "<br/>\n",
        "<br/>\n",
        "\\begin{equation}\n",
        "\\\\\n",
        "\\text{Positive words} = [\\text{'good', 'great', 'nice', 'happy', 'easy', 'yes', 'yeah', 'love', 'big', 'right', 'awesome', 'thank', 'thanks'}] \\\\\n",
        "\\text{Negative words} = [\\text{'bad', 'horrible', 'tough', 'sad', 'hard', 'no', 'shit', 'hate', 'little', 'wrong', 'stupid', 'sorry'}]\n",
        "\\end{equation} \\\\\n",
        "\n",
        "To stay in line with the utterance scoring of the other methods, each utterance got assigned its sentiment score by taking the average of the scores of all phrases within that utterance. Utterances that don’t contain any phrases are assigned a score that is based on the average of the scores of the nearest previous and next utterances that do already have a sentiment score. As the scores had to be between -1 and 1, the score of each utterance in a transcript was normalized by dividing by the highest absolute value among them. The final change from the method of Turney is that a phrase is given a score if it has at least two positive and two negative words near it, instead of at least four words each. All this lead to the following functions to assign scores to utterances:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaUQOSldbP9U"
      },
      "source": [
        "# For each utterance that wasn't assigned a score (either by not containing a phrase at all\n",
        "# or by not containing any with enough positive and negative words surrounding it), an average\n",
        "# of the scores of the nearest previous and next utterance is used\n",
        "\n",
        "def fill_nans(df):\n",
        "    replacements = df['predicted_score'].copy()\n",
        "    for i in range(len(df)):\n",
        "        if np.isnan(df['predicted_score'][i]):\n",
        "            new_values = []\n",
        "            j = i-1\n",
        "            while j >= 0:\n",
        "                if not np.isnan(df['predicted_score'][j]):\n",
        "                    new_values.append(1 / ((i - j) + 1) * df['predicted_score'][j])\n",
        "                    break\n",
        "                j -= 1\n",
        "            j = i+1\n",
        "            while j < len(df):\n",
        "                if not np.isnan(df['predicted_score'][j]):\n",
        "                    new_values.append(1 / ((j - i) + 1) * df['predicted_score'][j])\n",
        "                    break\n",
        "                j += 1\n",
        "            if new_values:\n",
        "                replacements[i] = np.mean(new_values)\n",
        "            else:\n",
        "                replacements[i] = 1\n",
        "    df['predicted_score'] = replacements\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_15w9Kp8bUPq"
      },
      "source": [
        "# Assigns a sentiment score between 0 and 1 for each utterance in the dataframe\n",
        "\n",
        "def add_scores(df, NEAR, pos_words, neg_words):\n",
        "    # Considers the previous and upcoming NEAR words surrounding the phrase\n",
        "    utt_lens = []\n",
        "    utt_scores = []\n",
        "    all_words = []\n",
        "    utt_idx = 0\n",
        "    df['predicted_score'] = np.nan\n",
        "    \n",
        "    \n",
        "    # Gets the length of each utterance so the semantic scores are assigned to the\n",
        "    # correct utterance, also a list with all words\n",
        "    for utt in df.text:\n",
        "        utt_lens.append(len([w for w in nltk.word_tokenize(utt) if w not in ['.', ',', '?', '!', '\\'']]))\n",
        "        all_words += [w for w in nltk.word_tokenize(utt) if w not in ['.', ',', '?', '!', '\\'']]\n",
        "\n",
        "    # Checks how many positive and negative words the enitre text contains\n",
        "    word_counter = Counter([w.lower() for w in all_words])\n",
        "    pos_hits = sum([word_counter[p] for p in pos_words]) + 0.01\n",
        "    neg_hits = sum([word_counter[n] for n in neg_words]) + 0.01\n",
        "    \n",
        "    for i in range(len(all_words) - 1):\n",
        "        # Keeps track of which utterance every possible phrase is in\n",
        "        if i >= sum(utt_lens[:utt_idx+1]) or i == len(all_words) - 2:\n",
        "            # When going to a new utterance, assigns the mean of the semantic scores\n",
        "            # of each phrase in the previous utterance as the score of that utterance\n",
        "            if utt_scores:\n",
        "                df['predicted_score'][utt_idx] = np.mean(utt_scores)\n",
        "            utt_idx += 1\n",
        "            utt_scores = []\n",
        "        # Creates list of neighbouring words of each phrase found, accounting for edge cases\n",
        "        if is_phrase(i, all_words):\n",
        "            neighbourhood = []\n",
        "            if NEAR > i:\n",
        "                neighbourhood += all_words[:i]\n",
        "            else:\n",
        "                neighbourhood += all_words[i-NEAR:i]\n",
        "            if i != len(all_words) - 2:\n",
        "                try:\n",
        "                    neighbourhood += all_words[i+2:i+2+NEAR]\n",
        "                except IndexError:\n",
        "                    neighbourhood += all_words[i+2:len(words)]\n",
        "            # Counts the amount of positive and negative words in the neighbourhood\n",
        "            neighbourhood_counter = Counter([w.lower() for w in neighbourhood])\n",
        "            pos_neigh_hits = sum([neighbourhood_counter[p] for p in pos_words]) + 0.01\n",
        "            neg_neigh_hits = sum([neighbourhood_counter[n] for n in neg_words]) + 0.01\n",
        "            # Applies the function from the paper to calculate the phrase's score\n",
        "            if pos_neigh_hits > 2 and neg_neigh_hits > 2:\n",
        "                score = np.log((pos_neigh_hits * neg_hits)/ (neg_neigh_hits * pos_hits))\n",
        "                utt_scores.append(score)\n",
        "                \n",
        "\n",
        "    # Normalizes each predicted sentiment score\n",
        "    df = fill_nans(df)\n",
        "    abs_max = max([max(df['predicted_score']), -min(df['predicted_score'])])\n",
        "    if abs_max:\n",
        "        df.loc[:, 'predicted_score'] += abs_max\n",
        "        df.loc[:, 'predicted_score'] /= (2*abs_max)\n",
        "    df.loc[df.predicted_score >= 0.5, 'predicted_score'] = 1.0\n",
        "    df.loc[df.predicted_score < 0.5, 'predicted_score'] = 0.0\n",
        "        \n",
        "\n",
        "    return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnS36uM_tUjN"
      },
      "source": [
        "### 5.3 Unsupervised Sentiment Prediction Using Word2Vec, K-means, and TF-IDF\r\n",
        "The general idea behind sentiment analysis is detecting a tone in a segment of speech. However, this can be quite difficult to achieve if the training data is not labeled. The method used below utilizes TF-IDF [(Spärck Jones, 1972)](https://pdfs.semanticscholar.org/4f09/e6ec1b7d4390d23881852fd7240994abeb58.pdf?source=post_page---------------------------), Word2Vec [(Mikolov et al., 2013)](https://arxiv.org/pdf/1310.4546.pdf) and K-means[(J MacQueen, 1967)](https://www.cs.cmu.edu/~bhiksha/courses/mlsp.fall2010/class14/macqueen.pdf).\r\n",
        "\r\n",
        "First, the datasets that will be used for training and evaluation are loaded.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-YXs5WtT_w"
      },
      "source": [
        "# Function that removes punctuation, lowercases everything (to normalize), tokenizes, and converts the labels to int\r\n",
        "def clean_data(df):\r\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\r\n",
        "    df['text'] = df['text'].str.lower()\r\n",
        "    df['text_tokenized'] = df['text'].apply(tokenizer.tokenize)\r\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_FWHEebtaRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4f5ae0-c696-4fc1-b6fc-898ed202f0cf"
      },
      "source": [
        "# download training dataset\r\n",
        "url = 'https://drive.google.com/uc?id=173Nk1f8wmK9MsmKTdbOdXA6fKEjD__8J'\r\n",
        "output = 'training_set.csv'\r\n",
        "gdown.download(url, output, quiet=False)\r\n",
        "df_train = pd.read_csv('training_set.csv', sep='\\t')\r\n",
        "\r\n",
        "# Normalize and clean text\r\n",
        "df_train = clean_data(df_train)\r\n",
        "text = df_train['text_tokenized'].values"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=173Nk1f8wmK9MsmKTdbOdXA6fKEjD__8J\n",
            "To: /content/training_set.csv\n",
            "100%|██████████| 1.24M/1.24M [00:00<00:00, 124MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2fQZU3bC8D8"
      },
      "source": [
        "\r\n",
        "\r\n",
        "Using gensim's Phrases and Phraser modules, the most common phrases can be extraced from the corpus. The parameter *min_count* can be utilized to create a lower boundry for the minimal frequency of terms in the corpus. This means that higher values of *min_count* result in a decreased number of terms in the final corpus.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udOM5gEDYdyM"
      },
      "source": [
        "optimized_terms = Phraser(Phrases(text, min_count=2))\r\n",
        "text_final = optimized_terms[text]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMY5y4QXH9xh"
      },
      "source": [
        "#### 5.3.1 Word2Vec\r\n",
        "First, in order to model the relationship between different terms in the dataset, Word2Vec [(Mikolov et al., 2013)](https://arxiv.org/pdf/1310.4546.pdf)is used. Each words is assigned a vector that represents its compositionality compared to other words in the corpus. For example, comparing the words *'King'* and *'Queen'* trained in cooperation with a large dataset might yield vectors that are roughly interpretable as\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "    \\text{King} = \\text{Male} + \\text{Royal}\\\\\r\n",
        "    \\text{Queen} = \\text{King} - \\text{Male} + \\text{Female}\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "Considering the size of the corpus and previous tests, a 300-dimensional Word2Vec model is built and trained using the corpus with added bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VcbkpJmcha1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec08fa1-558b-4a01-9883-f0d2ecaf8d71"
      },
      "source": [
        "modelw2v = Word2Vec(text_final,size=300)\r\n",
        "modelw2v.build_vocab(text_final, update=True)\r\n",
        "modelw2v.train(text_final, total_examples=modelw2v.corpus_count, epochs=30)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4174269, 6944010)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkPNHXCqdAsC"
      },
      "source": [
        "word_vectors = modelw2v.wv"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJtlOpnBclrz"
      },
      "source": [
        "#### 5.3.2 K-means Clustering\r\n",
        "Using Word2Vec, each word has been given a vector. These vectors can be utilized with the K-means algorithm in order to find clusters of words that are closer together. These clusters then contain words that are distinguishable as more or less positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlJV7HARcof_"
      },
      "source": [
        "model = KMeans(n_clusters=2, max_iter=10000, random_state=True, n_init=1000).fit(X=word_vectors.vectors.astype('double'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRWkdqZYJJTj"
      },
      "source": [
        "After training the K-means model, the obtained clusters have to be manually labeled according to which cluster is deemed more positive, and thus, which cluster is deemed more negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEi_PfzWJGlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421158e9-132a-40e8-e27a-96f2fbc09b10"
      },
      "source": [
        "print(word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None))\r\n",
        "print(word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('bethenny', 0.6760615110397339), ('guilty', 0.6636659502983093), ('loyal', 0.65386962890625), ('uncomfortable', 0.6520451307296753), ('say_anything', 0.6492599844932556), ('focused', 0.6368128657341003), ('cowboy_hat', 0.629563570022583), ('unbelievable', 0.6276184320449829), ('frank', 0.6256113052368164), ('too_young', 0.6254780292510986)]\n",
            "[('combat', 0.8258557319641113), ('free_agency', 0.810555636882782), ('team_rules', 0.808019757270813), ('rate', 0.8011363744735718), ('previous', 0.800624668598175), ('creatures', 0.7997298240661621), ('chompers', 0.7956754565238953), ('kicks', 0.7945824861526489), ('our_community', 0.7945696115493774), ('uk', 0.7945586442947388)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTJET35KJga1"
      },
      "source": [
        "Then, as the second and final manual step, the index of the more positive cluster must be entered, according to the perceived assignment of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5xOgOi0JfUw"
      },
      "source": [
        "# Enter the index of the positive cluster\r\n",
        "positive_cluster_index = 0\r\n",
        "\r\n",
        "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\r\n",
        "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGYwhbpVBfnt"
      },
      "source": [
        "Next, in order to create a metric that can help with classifying in the final step, the words are vectorized and assigned to a cluster. The distance, or of each word to their respective cluster is then connected to each word. Finally, a coëfficient is calculated by multiplying this distance to the respective cluster value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOjeoNgWBggy"
      },
      "source": [
        "def create_df_dict():\r\n",
        "\r\n",
        "    # Create vectors for each word\r\n",
        "    metrics_df = pd.DataFrame(word_vectors.vocab.keys())\r\n",
        "    metrics_df.columns = ['words']\r\n",
        "\r\n",
        "    # Assign words to a cluster using Sklearn's predict\r\n",
        "    metrics_df['vectors'] = metrics_df['words'].apply(lambda x: word_vectors[f'{x}'])\r\n",
        "    metrics_df['cluster'] = metrics_df['vectors'].apply(lambda x: model.predict([np.array(x)]))\r\n",
        "\r\n",
        "    # Unpack the values from list\r\n",
        "    metrics_df['cluster'] = metrics_df['cluster'].apply(lambda x: x[0])\r\n",
        "\r\n",
        "    # Assign words to cluster\r\n",
        "    metrics_df['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in metrics_df['cluster']]\r\n",
        "\r\n",
        "    # Assign the inverse distance to the closest cluster to each word\r\n",
        "    metrics_df['distance'] = metrics_df.apply(lambda x: 1/(model.transform([x['vectors']]).min()), axis=1)\r\n",
        "\r\n",
        "    # Calculate the sentiment coefficient\r\n",
        "    metrics_df['sentiment_coeff'] = metrics_df['distance'] * metrics_df['cluster_value']\r\n",
        "\r\n",
        "    sentiment_dict = dict(zip(metrics_df['words'].values, metrics_df['sentiment_coeff'].values))\r\n",
        "\r\n",
        "    return metrics_df, sentiment_dict"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvdTKAKMdvoG"
      },
      "source": [
        "#### 5.3.4 The Prediction Phase\r\n",
        "After each sequence has been transformed into its corresponding TF-IDF sequence, the prediction can be obtained by calculating the dot product of the TF-IDF scores and the sentiment coefficient, which is the overall sentiment multiplied by the predicted sentiment cluster, which has a value of either -1 (negative sentiment) or 1 (positive sentiment):\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "\\text{Sentiment prediction = TF-IDF score}\\bullet(\\text{closeness}_{min}\\cdot \\text{cluster value})\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "which is then transformed using the condition described in section 2.\r\n",
        "\r\n",
        "Now that the model is completed, the results phase contains more code for calculations performed on the validation dataset. Finally, these labels can be compared to the labeled data, which is demonstrated in section 6.1.3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWjLMGPzAz6p"
      },
      "source": [
        "### 5.4 DistilBERT Sentiment Prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--uJERfn9ZbE"
      },
      "source": [
        "In this Deep Learning-based method, a smaller and faster version of the previously mentioned BERT model was used. This model is called DistilBERT and is 40% smaller and 60% faster than BERT, all while retaining more than 95% of BERT’s performance [(Sanh et al., 2019)](https://arxiv.org/pdf/1910.01108). DistilBERT is pretrained and was finetuned on the labeled training dataset (mentioned in Section 4) for the sentiment prediction task of podcast dialogues. Finally, the model was evaluated on the labeled validation set. During this evaluation, parameter-tuning was done with the learning-rate and the weights of the model with the best metrics were saved. The training and inference code for this model can be found on the [Github repository](https://github.com/bartvanvulpen/podcastDA) of this project, under `BERT_training.ipnyb` and `BERT_inference.ipynb` respectively. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXBqbmPJ2iu1"
      },
      "source": [
        "### 5.5 Mining Sentiment Patterns\n",
        "From the previously described methods, the best performing method in terms of accuracy, recall, precision and F1-score was applied on the dataset containing 36,318 podcast dialogue with 3,010,296 utterances. The outputs (sentiment labels per utterance per dialogue) were used to mine and analyze sentiment paterns in podcast dialogues.\n",
        "\n",
        "First, some general sentiment statistics were mined from the output produced by the best performing model. These statistic included the number of positive and negative utterances in podcasts in total as well as the number of positive labeled and negative labeled podcast episodes.\n",
        "Secondly, sentiment patterns within podcast dialogues were mined. This consists of finding the most common sentiment patterns (e.g. '+++' or '+-+') and longest patterns within podcast dialogues. Also, based on the output sentiment labels, the gradients of the sentiment within some podcast dialogues were visualized. Finally, an aggregration of the sentiment gradients of all podcast episodes was done to visualize the total sentiment gradient of podcasts in general. In order to be able to aggregrate, the output data first needed to be scaled in such way that each array of utterance labels for each dialogue had the same length. The function that scaled the data was based on percentages of segmentations within such an array of utterance labels and is declared below. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-qM-9XxEqYB"
      },
      "source": [
        "def segment_seqs(x):\n",
        "    \"\"\"\n",
        "    This function segments a list into sublists where each\n",
        "    sublist corresponds to a repetitive sequence of 0's or 1's\n",
        "    in the given list x\n",
        "    \"\"\"\n",
        "    if not x:\n",
        "        return []\n",
        "    result = [[x[0]]]\n",
        "    j = 0\n",
        "    for i in range(1, len(x)):\n",
        "        if x[i] != x[i - 1]:\n",
        "            result.append([])\n",
        "            j += 1\n",
        "        result[j].append(x[i])\n",
        "        \n",
        "    return result\n",
        "\n",
        "def scale_data(sentiment_data):\n",
        "    \"\"\"\n",
        "    Scale a list with sentiments (0's and 1's) to the max_length of the data\n",
        "    in order to aggregrate the data.\n",
        "    \"\"\"\n",
        "    max_len = max([len(i) for i in sentiment_data])\n",
        "    scaled_data = np.zeros((len(sentiment_data), max_len))\n",
        "    \n",
        "    for index, x in tqdm(enumerate(sentiment_data)):\n",
        "        old_len = len(x)\n",
        "        segmented_x = segment_seqs(x)\n",
        "\n",
        "        scaled_x = []\n",
        "        for item in segmented_x:\n",
        "\n",
        "            bit = item[0]\n",
        "            percentage = len(item)/old_len\n",
        "        \n",
        "            n = int(np.round(max_len * percentage))\n",
        "            \n",
        "            for s in n*[bit]:\n",
        "                scaled_x.append(s)\n",
        "  \n",
        "        if len(scaled_x) == max_len:\n",
        "            scaled_data[index] = scaled_x\n",
        "\n",
        "        else:\n",
        "            # do padding before and after, to make length equal to max length of the data\n",
        "            difference = max_len - len(scaled_x)\n",
        "    \n",
        "            if difference > 0:\n",
        "  \n",
        "                pad_before = difference // 2\n",
        "                pad_after = (difference // 2) + (difference % 2)\n",
        "\n",
        "                scaled_x = pad_before * [scaled_x[0]] + scaled_x + pad_after * [scaled_x[-1]]\n",
        "\n",
        "                if len(scaled_x) == max_len:\n",
        "                    scaled_data[index] = scaled_x\n",
        "\n",
        "                else:  \n",
        "                    raise Exception(\"Length of scaled list not equal to max length of the data\") \n",
        "                \n",
        "            elif difference < 0: \n",
        "                \n",
        "                diff = abs(difference)\n",
        "                remove_before = diff // 2\n",
        "                remove_after = (diff // 2) + (diff % 2)\n",
        "\n",
        "                scaled_x = scaled_x[remove_before:len(scaled_x)-remove_after]\n",
        "\n",
        "                if len(scaled_x) == max_len:\n",
        "                    scaled_data[index] = scaled_x\n",
        "\n",
        "                else:\n",
        "                    raise Exception(\"Length of scaled list not equal to max length of the data\") \n",
        "             \n",
        "    return scaled_data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWnucCiZAKvB"
      },
      "source": [
        "## 6 Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8soXDda33ffh"
      },
      "source": [
        "### 6.1 Metrics\n",
        "First we download the validation set used to calculate the validation metrics. For validation of the Neighbourhood-based Method, the full labeled .csv-files were downloaded.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHn3fBay-FwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b994cf6f-b711-48df-a576-47178d259d87"
      },
      "source": [
        "# load validation set for lexicon-based, Word2Vec + K-means + TD-IDF and BERT methods\n",
        "urllib.request.urlretrieve('https://drive.google.com/uc?id=1Xf3LGvIBYA7YqUFy473qowk4V4MT3t4g&export=download', 'validation_set.csv')\n",
        "val_df = pd.read_csv('validation_set.csv', sep='\\t')\n",
        "val_df['sentiment_score'].value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    887\n",
              "0.0    405\n",
              "Name: sentiment_score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59hgFG6Qb5v7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599fd984-00e8-45a2-8c2c-921070f3ff89"
      },
      "source": [
        "# Load validation set for neighbourhood-based method\n",
        "gdown.download('https://drive.google.com/uc?id=1aqE8yS7Lf8GfljmFEuW5pd3i5S2raW1B', 'separate_csv_files.zip', quiet=False)\n",
        "with zipfile.ZipFile('separate_csv_files.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aqE8yS7Lf8GfljmFEuW5pd3i5S2raW1B\n",
            "To: /content/separate_csv_files.zip\n",
            "100%|██████████| 671k/671k [00:00<00:00, 94.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnxqXfNe6F9l"
      },
      "source": [
        "#### 6.1.1 Lexicon based method\n",
        "\n",
        "The SentiWordNet approach achieved a total accuracy of 68%, along with a decent recall on positive labels. However, it performed bad in terms of recall and precision on negative labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpL_69s6BEb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01510c96-9a68-400f-d4c0-5591a85526a3"
      },
      "source": [
        "# calculate metrics for SentiWordNet method\n",
        "target_labels = val_df['sentiment_score'].values\n",
        "predicted_labels = []\n",
        "for sample in tqdm(val_df['text']):\n",
        "    predicted_sentiment = SentiWordNet_sentiment(sample)\n",
        "    predicted_labels.append(predicted_sentiment)\n",
        "\n",
        "predicted_labels = np.array(predicted_labels)  \n",
        "print\n",
        "print('\\n\\n', classification_report(target_labels, predicted_labels))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1292/1292 [00:11<00:00, 111.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.48      0.42      0.45       405\n",
            "         1.0       0.75      0.80      0.77       887\n",
            "\n",
            "    accuracy                           0.68      1292\n",
            "   macro avg       0.62      0.61      0.61      1292\n",
            "weighted avg       0.67      0.68      0.67      1292\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EOxtyAc-1Hj"
      },
      "source": [
        "The VADER sentiment classifier achieved better performance in terms of accuracy and F1-score (73% and 83% respectively) on positive labels than the SentiWordNet approach. However, VADER performed much worse in terms of recall on negative labels, only 26%.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6cpac1QBE_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a095d2-171b-4894-f424-a0396e8b57b8"
      },
      "source": [
        "predicted_labels = []\n",
        "for sample in tqdm(val_df['text']):\n",
        "    predicted_sentiment = VADER_sentiment(sample)\n",
        "    predicted_labels.append(predicted_sentiment)\n",
        "\n",
        "predicted_labels = np.array(predicted_labels)  \n",
        "print('\\n\\n', classification_report(target_labels, predicted_labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1292/1292 [00:14<00:00, 92.07it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.26      0.38       405\n",
            "         1.0       0.74      0.94      0.83       887\n",
            "\n",
            "    accuracy                           0.73      1292\n",
            "   macro avg       0.71      0.60      0.60      1292\n",
            "weighted avg       0.72      0.73      0.69      1292\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTihwQmh57Jl"
      },
      "source": [
        "#### 6.1.2 Neighbourhood-based Method\n",
        "\n",
        "To test the performance of the Neighbourhood-based Method, it was important to first find the most optimal parameter values for the NEAR value and the lists of positive and negative words that should be looked for. To do this, the following performance testing and parameter optimization functions were used:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sFRoUg-diLx"
      },
      "source": [
        "# Returns a classification report that shows the performance of the predicted sentiment scores\n",
        "# when compared to the actual sentiment scores. Takes n randomly chosen podcast episodes with at\n",
        "# least min_len utterances from a folder with labeled csvs, or all of them if n is too large\n",
        "# and outputs the classification report.\n",
        "\n",
        "def compare_scores(labeled_folder, NEAR, pos_words, neg_words, n, min_len, output_dict):\n",
        "    # Hides warnings\n",
        "    pd.options.mode.chained_assignment = None\n",
        "    \n",
        "    # Gets all file names within the folder\n",
        "    filenames = [f for f in listdir(labeled_folder) if isfile(join(labeled_folder, f))]\n",
        "    np.random.shuffle(filenames)\n",
        "    dfs = []\n",
        "    c = 0\n",
        "    # Looks for up to n podcast episodes with at least min_len utterances\n",
        "    for filename in filenames:\n",
        "        df = pd.read_csv(labeled_folder + '/' + filename, sep='\\t')\n",
        "        if len(df) >= min_len:\n",
        "            dfs.append(df)\n",
        "            c += 1\n",
        "            if c == n:\n",
        "                break\n",
        "        \n",
        "    # Returns the classification report for the performance of the classification of the \n",
        "    # sentiments.\n",
        "    if len(dfs) == 1:\n",
        "        df = add_scores(df, NEAR, pos_words, neg_words)\n",
        "        return classification_report(list(df.sentiment_score.values), \n",
        "                                       list(df.predicted_score.values), zero_division=0, \n",
        "                                     output_dict=output_dict)\n",
        "    total_scores = []\n",
        "    total_predicted = []\n",
        "    for df in dfs:\n",
        "        df = add_scores(df, NEAR, pos_words, neg_words)\n",
        "        total_scores += list(df.sentiment_score.values)\n",
        "        total_predicted += list(df.predicted_score.values)\n",
        "    return classification_report(total_scores, total_predicted, zero_division=0, \n",
        "                                 output_dict=output_dict)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Nt0exXdily"
      },
      "source": [
        "# Obtains the best performing NEAR value and samples of the positive and negative word lists\n",
        "# by randomly generating n parameter sets, doing a brief performance check on each, and then\n",
        "# more extensively testing those that initially performed well. Returns the most optimal \n",
        "# parameter set.\n",
        "\n",
        "def optimize_params(n, pos_words, neg_words):\n",
        "    best_params = []\n",
        "    best_accuracy = 0.0\n",
        "    good_params = []\n",
        "    \n",
        "    # Randomly generates NEAR value between 50 and 1000 and samples of the word lists\n",
        "    for i in range(n):\n",
        "        NEAR = np.random.randint(1, 20) * 50\n",
        "        sample_size = np.random.randint(len(pos_words) - 3, len(pos_words))\n",
        "        pos_sample = np.random.choice(pos_words, sample_size, replace=False)\n",
        "        neg_sample = np.random.choice(neg_words, sample_size, replace=False)\n",
        "        metrics = compare_scores('separate_csv_files', NEAR, \n",
        "                                       pos_sample, neg_sample, 1, 50, True)\n",
        "        # Parameter sets that predict both positive and negative sentiments and have decent\n",
        "        # metrics in this initial test are considered for more extensive testing\n",
        "        if '0.0' in metrics.keys() and '1.0' in metrics.keys():\n",
        "            if metrics['accuracy'] > 0.6 and metrics['0.0']['recall'] > 0.45 and metrics['0.0']['recall'] > 0.45:\n",
        "                good_params.append((NEAR, pos_sample, neg_sample))\n",
        "                \n",
        "    # All well-performing sets are then tested 30 times each, with the set that has the best\n",
        "    #average accuracy then being returned\n",
        "    for params in good_params:\n",
        "        (NEAR, pos_sample, neg_sample) = params\n",
        "        accuracy = compare_scores('separate_csv_files', NEAR, \n",
        "                                   pos_sample, neg_sample, 30, 50, True)['accuracy']\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = np.mean(accuracies)\n",
        "            best_params = (NEAR, pos_sample, neg_sample)\n",
        "    return best_params, best_accuracy"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2gS7SrmdndD"
      },
      "source": [
        "This was ran 2000 times, each time generating a random value between 50 and 1000 in steps of 50 for the NEAR value and taking a random sample of the positive and negative words, leaving out up to 3 of each list. From this, it was found that the most optimal parameters were a NEAR value of 350 and the following word lists:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Positive Words} = \\text{['yes', 'yeah', 'love', 'easy', 'great', 'nice',\n",
        "                     'happy', 'awesome','thanks', 'thank']} \\\\\n",
        "\\text{Negative Words} = \\text{['little', 'wrong', 'hard', 'stupid', 'horrible',\n",
        "                     'shit', 'sad', 'sorry', 'no', 'tough']} \\\\\n",
        "\\end{equation}\n",
        "\n",
        "Using these parameters in the compare_scores function on 5 randomly selected labeled podcast episodes in the validation set with at least 150 utterances each lead to the following classification report:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0MShG4d7Qfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25467b5e-f7ca-430b-c69e-a675c23747d7"
      },
      "source": [
        "optimized_params = (350, \n",
        "                    ['yes', 'yeah', 'love', 'easy', 'great', 'nice',\n",
        "                     'happy', 'awesome','thanks', 'thank'], \n",
        "                    ['little', 'wrong', 'hard', 'stupid', 'horrible',\n",
        "                     'shit', 'sad', 'sorry', 'no', 'tough'])\n",
        "\n",
        "\n",
        "print(compare_scores('separate_csv_files', optimized_params[0], optimized_params[1],\n",
        "               optimized_params[2], 5, 150, False))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.35      0.49      0.41       356\n",
            "         1.0       0.66      0.52      0.59       678\n",
            "\n",
            "    accuracy                           0.51      1034\n",
            "   macro avg       0.51      0.51      0.50      1034\n",
            "weighted avg       0.56      0.51      0.53      1034\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrRTsr6aCZ31"
      },
      "source": [
        "#### 6.1.3 Unsupervised Sentiment Prediction Using Word2Vec, K-means, and TF-IDF\r\n",
        "For the results, the validation set is first cleaned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1eyliqGbZIp"
      },
      "source": [
        "df_val = clean_data(val_df)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G35cn2UtbOdy"
      },
      "source": [
        "In order to counteract things such as stopwords, the TF-IDF values of every sequence are calculated and inserted into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NsBHH9tbQqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1600c06-6a13-41e1-9a4a-ec6483e24766"
      },
      "source": [
        "# Vectorize the sequences\r\n",
        "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\r\n",
        "tfidf.fit(df_val['text'])\r\n",
        "\r\n",
        "# Get the names of each feature\r\n",
        "features = pd.Series(tfidf.get_feature_names())\r\n",
        "\r\n",
        "# Transform the text into their respective TF-IDF values\r\n",
        "transformed = tfidf.transform(df_val['text'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGga4_BbrVpf"
      },
      "source": [
        "After obtaining the TF-IDF values, the final step is to calculate the predicted label by taking the dot product of the TF-IDF values and the sentiment coefficients of each sentence.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztCRBoS7amrC"
      },
      "source": [
        "metrics_df, sentiment_dict = create_df_dict()\r\n",
        "\r\n",
        "# Create a dictionary of every word and its corresponding TF-IDF value\r\n",
        "def create_tfidf_dictionary(x, transformed_file, features):\r\n",
        "    vector_coo = transformed_file[x.name].tocoo()\r\n",
        "    vector_coo.col = features.iloc[vector_coo.col].values\r\n",
        "    return dict(zip(vector_coo.col, vector_coo.data))\r\n",
        "\r\n",
        "def replace_tfidf_words(x, transformed_file, features):\r\n",
        "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \r\n",
        "    return list(map(lambda y:dictionary[f'{y}'], x['text'].split()))\r\n",
        "\r\n",
        "# Replaces a word with its respective sentiment value\r\n",
        "def replace_sentiment_words(word, sentiment_dict):\r\n",
        "    try:\r\n",
        "        return sentiment_dict[word]\r\n",
        "    except KeyError:\r\n",
        "        return 0\r\n",
        "\r\n",
        "replaced_tfidf_scores = df_val.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\r\n",
        "replaced_closeness_scores = df_val['text'].apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))\r\n",
        "\r\n",
        "# Create new dataframe for final calculations\r\n",
        "df_kmeans = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, df_val['text'], df_val['sentiment_score']]).T\r\n",
        "df_kmeans.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment_score']\r\n",
        "\r\n",
        "# Take the dot product to determine if a segment is mostly positive or mostly negative\r\n",
        "df_kmeans['prediction'] = df_kmeans.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_iK__lNsLc5"
      },
      "source": [
        "Finally, the prediction can be made by labeling everything according to the condition outlined in section 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGGJWPmwCaSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb8ad7c-4409-41dd-ee4f-357210147a80"
      },
      "source": [
        "# Predict the label and convert to the same datatype\r\n",
        "df_kmeans['prediction'] = (df_kmeans['prediction']>=0).astype('int8')\r\n",
        "df_kmeans['sentiment_score'] = df_kmeans['sentiment_score'].astype('int8')\r\n",
        "\r\n",
        "y_true_kmeans = df_kmeans['sentiment_score']\r\n",
        "y_pred_kmeans = df_kmeans['prediction']\r\n",
        "\r\n",
        "# Display the final scores\r\n",
        "print('Confusion Matrix\\n',confusion_matrix(y_true_kmeans,y_pred_kmeans))\r\n",
        "print(classification_report(y_true_kmeans, y_pred_kmeans))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            " [[172 233]\n",
            " [449 438]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.42      0.34       405\n",
            "           1       0.65      0.49      0.56       887\n",
            "\n",
            "    accuracy                           0.47      1292\n",
            "   macro avg       0.46      0.46      0.45      1292\n",
            "weighted avg       0.53      0.47      0.49      1292\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oInoMkiY_bKr"
      },
      "source": [
        "#### 6.1.4 DistilBERT Classifier\n",
        "\n",
        "Below the code for evaluating the DistilBERT sentiment classifier can be executed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCcO8m7plTzY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "bb041959-7812-49bb-e002-b1936dd72ede"
      },
      "source": [
        "# safely download best saved model from Google Drive\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1bYN56DXNp_TZHuA0-K4hER_PLddSaLZL'\n",
        "output = 'DistilBERT_best_model.pt'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bYN56DXNp_TZHuA0-K4hER_PLddSaLZL\n",
            "To: /content/DistilBERT_best_model.pt\n",
            "268MB [00:01, 226MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DistilBERT_best_model.pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENPqvtzxGgY_"
      },
      "source": [
        "%%capture\n",
        "# get pretrained DistilBERT model from Transformers library\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=1).to(device)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Load best trained model weights, see BERT_training.ipynb in the github for the training script\n",
        "model.load_state_dict(torch.load('DistilBERT_best_model.pt', map_location=device))\n",
        "model.eval()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEAUFqOmg4l"
      },
      "source": [
        "# Tokenize validation data\n",
        "tokenized_utterances_val = val_df.text.apply(lambda x: tokenizer.encode(x,add_special_tokens=True))\n",
        "\n",
        "# Make sure length of utterances are not greater than 512\n",
        "for index, utt in enumerate(tokenized_utterances_val):\n",
        "    if len(utt) > 512:\n",
        "      tokenized_utterances_val[index] = utt[:512]\n",
        "\n",
        "# Pad utterances for validation set\n",
        "max_len = max(map(len,tokenized_utterances_val))\n",
        "padded_utterances_val = np.array([ i+[0]*(max_len-len(i))  for i in tokenized_utterances_val])\n",
        "attention_masked_utterances_val = np.where(padded_utterances_val != 0,1,0)\n",
        "\n",
        "# Create tensors\n",
        "X_val = torch.tensor(padded_utterances_val, device=device)\n",
        "X_val_attention = torch.tensor(attention_masked_utterances_val, device=device)\n",
        "y_val = torch.tensor(np.array(val_df.sentiment_score.values)[:,np.newaxis], dtype=torch.float32)\n",
        "\n",
        "val_dataset = TensorDataset(X_val, X_val_attention)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrSnSWtqWaIr"
      },
      "source": [
        "def sigmoid(x):\n",
        "  \"\"\"\n",
        "  Returns the sigmoid value of x\n",
        "  \"\"\"\n",
        "  return 1 / (1 + np.exp(-x)) "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIllGnYXqJCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570959c5-cd6d-4eb8-90e3-346fa925c628"
      },
      "source": [
        "# evaluate loaded model on validation set\n",
        "preds = np.zeros([len(val_dataset), 1])\n",
        "model.eval()\n",
        "for i, (x_batch, x_mask) in enumerate(val_loader):\n",
        "  outputs = model(x_batch.to(device),attention_mask=x_mask.to(device))\n",
        "  y_pred = sigmoid(outputs[0].detach().cpu().numpy())\n",
        "  preds[i*16:(i+1)*16, :] = y_pred\n",
        "\n",
        "print('ROC-AUC score:', metrics.roc_auc_score(y_val, preds))\n",
        "print()\n",
        "\n",
        "pred_labels = []\n",
        "for p in preds:\n",
        "  if p > 0.5:\n",
        "    pred_labels.append(1)\n",
        "  else:\n",
        "    pred_labels.append(0)\n",
        "y_target = list([int(x) for x in y_val])\n",
        "\n",
        "print(metrics.classification_report(y_target, pred_labels))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC-AUC score: 0.8582404275752641\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.60      0.65       405\n",
            "           1       0.83      0.89      0.86       887\n",
            "\n",
            "    accuracy                           0.80      1292\n",
            "   macro avg       0.77      0.74      0.75      1292\n",
            "weighted avg       0.79      0.80      0.79      1292\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8QL3Be0wdhu"
      },
      "source": [
        "The performance of the DistilBERT sentiment classifier is good in terms of accuracy (80%). The ROC-AUC score, a measure for the ability of a classifier model to distinguish between classes, is 85.6%. \n",
        "\n",
        "The model also seems to perform well with a precision of 71% and 83% for negative labels and positive labels respectively.\n",
        "However, although the recall of positive labels is high with 89%, the recall of negative labels is mediocre with only 60&. This results in a lower F1-score for negative labels. Overall, this method performed the best in the sentiment prediction task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR0yG3KX-5KJ"
      },
      "source": [
        "As can be seen in this section, the DistilBERT classifier achieved the best results and will be used to analyze the sentiment on the dataset containing more than 35,000 dialogues with more than 3,000,000 utterances. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60VmpyZg3hCn"
      },
      "source": [
        "### 6.2 Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGYq9YU44but",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f916d4-8935-4b6e-dee9-421ea8bc9545"
      },
      "source": [
        "# download result files from Google Drive\n",
        "urllib.request.urlretrieve('https://drive.google.com/uc?id=12b9wEATIfEaNwXC5sTyC8u4VTAT_6di3&export=download', 'results_p1.txt')\n",
        "urllib.request.urlretrieve('https://drive.google.com/uc?id=1oUhIiDgaGvxHZZeVQc2EsdlnF_D8EQF-&export=download', 'results_p2.txt')\n",
        "\n",
        "# open files with pickle\n",
        "with open('results_p1.txt', \"rb\") as fp:   # Unpickling\n",
        "    data_p1 = pickle.load(fp)\n",
        "with open(\"results_p2.txt\", \"rb\") as fp:   # Unpickling\n",
        "    data_p2 = pickle.load(fp)\n",
        "        \n",
        "# merge data and show first stats\n",
        "data = data_p1 + data_p2 \n",
        "total_utt = sum(len(x) for x in data)\n",
        "print('Number of dialogues:', len(data))\n",
        "print('Number of utterances:', total_utt)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of dialogues: 36318\n",
            "Number of utterances: 3010296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3P8e98z15hs"
      },
      "source": [
        "#### 6.2.1 Sentiment Statistics in podcasts in general\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLXIVHv68UTp"
      },
      "source": [
        "Below you can see the number and percentage of negative and positive labeled podcast episodes. As you can see, there exists much more positive podcast episodes than negative ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prTuE6bp8PrZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "122ace26-a09b-4fed-87b7-90dc1c4d2cf9"
      },
      "source": [
        "# get total sentiment of dialogues (positive or negative)\n",
        "def dialogue_sentiments(sentiment_data):\n",
        "    sentiments = []\n",
        "    for d in sentiment_data:\n",
        "        try:\n",
        "            sentiments.append(mode(d))\n",
        "        except:\n",
        "            # in case of equal counts, choose negative\n",
        "            sentiments.append(0)\n",
        "    return sentiments  \n",
        "sents = dialogue_sentiments(data) \n",
        "\n",
        "# calculate total counts for positive and negative podcasts\n",
        "pos_count = sents.count(1)\n",
        "neg_count = sents.count(0)\n",
        "print('Total positive podcast episodes:', pos_count)\n",
        "print('Total negative podcast episodes:', neg_count)\n",
        "\n",
        "\n",
        "# plot pie chart\n",
        "labels = 'Positive', 'Negative'\n",
        "myColors = ((0.467, 0.867, 0.467, 1.0), (1.0, 0.412, 0.38, 1.0))\n",
        "sizes = [pos_count, neg_count]\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, explode=[0.1, 0.1], autopct='%1.1f%%',\n",
        "        shadow=False, startangle=90, colors = myColors)\n",
        "ax1.axis('equal')\n",
        "plt.title('Positive vs negative podcast dialogues')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total positive podcast episodes: 34764\n",
            "Total negative podcast episodes: 1554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBHhlXq767Us"
      },
      "source": [
        "Below you can see the number and percentage of negative and positive labeled podcast dialogue utterances. As you can see, there exists much more positive utterances than negative ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeGaTIPy1gP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ac9974ec-ce0f-4b1d-f3e0-6c3620faf2be"
      },
      "source": [
        "pos_utt_count = [item for sublist in data for item in sublist].count(1)\n",
        "neg_utt_count = [item for sublist in data for item in sublist].count(0)\n",
        "\n",
        "print('Total positive utterannces:', pos_utt_count)\n",
        "print('Total negative utterances:', neg_utt_count)\n",
        "\n",
        "# plot pie chart\n",
        "labels = 'Positive', 'Negative'\n",
        "myColors = ((0.467, 0.867, 0.467, 1.0), (1.0, 0.412, 0.38, 1.0))\n",
        "sizes = [pos_utt_count, neg_utt_count]\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, explode=[0.05, 0.05], autopct='%1.1f%%',\n",
        "        shadow=False, startangle=90, colors = myColors)\n",
        "ax1.axis('equal')\n",
        "plt.title('Positive vs negative podcast dialogue utterances')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total positive utterannces: 2201976\n",
            "Total negative utterances: 808320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqe8iPjWBOAl"
      },
      "source": [
        "The longest negative and postive chain of utterances within a podcast dialogue is shown in the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJevmN0FBJLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508fca58-9755-4cdd-9402-75a3e2ce301a"
      },
      "source": [
        "# get length of longest sequence of positive utterances and longest sequence of negative utterances of a dialogue\n",
        "def longest_sequence(sentiment_data, sentiment):\n",
        "    longest = []\n",
        "    for d in sentiment_data:\n",
        "        c, max_val = 0, 0\n",
        "        for s in d: \n",
        "            # add to or reset running count\n",
        "            c = c + 1 if s == sentiment else 0 \n",
        "\n",
        "            max_val = max([c, max_val]) \n",
        "        longest.append(max_val)\n",
        "\n",
        "    return longest  \n",
        "\n",
        "longest_pos = max(longest_sequence(data, 1))\n",
        "longest_neg = max(longest_sequence(data, 0))\n",
        "print('Longest positive sequence of utterances in a podcast dialogue:', longest_pos)\n",
        "print('Visualization:', colored(longest_pos * '+', 'green'))\n",
        "print('Longest negative sequence of utterances in a podcast dialogue:', longest_neg)\n",
        "print('Visualization:', colored(longest_neg * '-', 'red'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest positive sequence of utterances in a podcast dialogue: 116\n",
            "Visualization: \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
            "Longest negative sequence of utterances in a podcast dialogue: 32\n",
            "Visualization: \u001b[31m--------------------------------\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMWmfcq9xOG"
      },
      "source": [
        "#### 6.2.2 Sentiment Patterns Found within Podcast Episodes\n",
        "\n",
        "Several patterns have been mined within dialogues. Below you can see how many times they occur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-yn0oA6cn3"
      },
      "source": [
        "# TODO: convert below function to measure percentages within dialogues (what are the most common pattern within a dialogue etc)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pztKO96x6FPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232a4da2-2859-4375-a41a-776bc7604572"
      },
      "source": [
        "# pattern example: +++ = [1, 1, 1], +-+ = [1, 0, 1]\n",
        "patterns = [[1, 1, 1], [0, 0, 0], [1, 0, 1], [0, 1, 0], [1, 0], [0, 1]]\n",
        "# Count sentiment patterns within podcasts\n",
        "def pattern_occurences(sentiment_data, pattern):\n",
        "  p_counts = []\n",
        "  for d in sentiment_data:\n",
        "      c = sum(1 for i in range(len(d)) if d[i:i+len(pattern)]==pattern)\n",
        "      p_counts.append(c)\n",
        "  return p_counts\n",
        "\n",
        "# function to convert bitstring list to a pos/neg string\n",
        "def sent_list_to_string(l):\n",
        "  new_l = []\n",
        "  for item in l:\n",
        "    if item == 0:\n",
        "      new_l.append('-')\n",
        "    else:\n",
        "      new_l.append('+')\n",
        "  return ''.join(new_l) \n",
        "\n",
        "for pattern in patterns:\n",
        "  pattern_occ = pattern_occurences(data, pattern)   \n",
        "  print('Total amounts of pattern {} in podcast episodes: '.format(sent_list_to_string(pattern)), sum(pattern_occ))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total amounts of pattern +++ in podcast episodes:  1295896\n",
            "Total amounts of pattern --- in podcast episodes:  134829\n",
            "Total amounts of pattern +-+ in podcast episodes:  328577\n",
            "Total amounts of pattern -+- in podcast episodes:  155487\n",
            "Total amounts of pattern +- in podcast episodes:  500643\n",
            "Total amounts of pattern -+ in podcast episodes:  500420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5XSqmIFDY9p"
      },
      "source": [
        "Below you can see the gradient of the sentiment of several podcast episodes. The red marked areas represent negative talking, where the green areas represent positive talking. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M_7rseaEJy_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "171f6af9-2a85-4f5d-887c-080beee2450d"
      },
      "source": [
        "# show a sentimennt visualization of sample at index\n",
        "def sentiment_progress_visualize(sentiment_data, i):\n",
        "    x = sentiment_data[i]\n",
        "    fig, ax = plt.subplots(figsize=(20,0.25))\n",
        "    ax.set(xlabel=i, ylabel='Episode progress')\n",
        "    myColors = ((1.0, 0.412, 0.38, 1.0), (0.467, 0.867, 0.467, 1.0))\n",
        "    cmap = LinearSegmentedColormap.from_list('Custom', myColors, len(myColors))          \n",
        "    seaborn.heatmap([x], square=False, xticklabels=False, yticklabels=False ,cmap=cmap, cbar=False)\n",
        "    plt.xlabel('Dialogue duration ⟶')\n",
        "    plt.show()\n",
        "\n",
        "# visualize\n",
        "max_v = 10\n",
        "for i in range(len(data)):\n",
        "    sentiment_progress_visualize(data, i) \n",
        "    if i == max_v:\n",
        "        break"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAAApCAYAAABtNM/XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFu0lEQVR4nO3dX6hlZRnH8e9vmrSgnEydCEIGI0oCm1CkxJFzJQRFjGUXSRn0By+KjIYagpqZgpr+DxUp0Y0GoU1k9IdExT+NWckMk1NCeaEWBDUIVipRzfB0cd5du90+Zx/d65zzHuf7udnrvGu9z3retfY+e5/nvGvtVBWSJEmSJElaf5vWOwFJkiRJkiQtslAjSZIkSZLUCQs1kiRJkiRJnbBQI0mSJEmS1AkLNZIkSZIkSZ3YvNzK3Q/vXvWvhNr/hePLrt+9a+vcMWYZYh8riTGvecfZkyGO11ocj7U4r7OsZJyz8lyL5+8Q52PecQyxj5V4thxPPT0b5X1giNfRvGNZq+dvD6/FXs77vHo53kPYKHn2YKO8dw+RxxB6+LtlCBvld2Mvx7uHz9lD6CXPXvLowf7z9mepdc6okSRJkiRJ6oSFGkmSJEmSpE5YqJEkSZIkSeqEhRpJkiRJkqROWKiRJEmSJEnqhIUaSZIkSZKkTliokSRJkiRJ6oSFGkmSJEmSpE5YqJEkSZIkSeqEhRpJkiRJkqROWKiRJEmSJEnqhIUaSZIkSZKkTliokSRJkiRJ6kSqar1zkCRJkiRJEs6okSRJkiRJ6oaFGkmSJEmSpE5YqJEkSZIkSeqEhRpJkiRJkqROWKiRJOkUleRkkl8leTDJA0k+nGRTW3dRkq/M6L+Q5Edrk+3ykjya5OyBYi0kuWTs52uSvHOI2JIkSbNsXu8EJEnSuvl7VW0HSLIV+DZwBrCnqg4Dh9czudWUZHNVnVhi9QLwJHAfQFVdv1Z5SZIkOaNGkiRRVceB9wHvz6L/zJZJcnGSnyc5muS+JK+c7J/kxUm+n+RYkl8kuaC1n5Pk9jZr55tJfp/k7CTbkvxmrP+uJHvb8suT3JrkSJJDSV41ZX9nJbltFBdIa18u7t1JDiQ5DHwwyZuS/LKN644kL0myDbgG+FCbbbQjyd4ku1qM7W18x5LckuTMsdifTXJ/koeS7JjnfCS5NMlZ88SQJEkbk4UaSZIEQFU9DDwH2Dqx6rfAjqp6LfAJ4NNTuu8DjlbVBcDHgBtb+x7gzqp6NfBd4NwVpPIN4ANVdSGwC/j6lG32APe2uLesMC7AaVV1UVV9EbgXeF0b103AR6rqUeB64MtVtb2qDk30vxH4aBvnr1seI5ur6mLg2on2Z+JM4CcWayRJOvV46ZMkSZplC3BDklcABTx3yjaXAm8BqKo724yXM1r7ztZ+a5LHl9tRkhcAlwAHk4yaT5+y6WXAFS3uj2fFHXPz2PLLgJuTvBQ4DXhkRm5bgBdV1T2t6Qbg4Ngm32uPR4BtU/pfC7xnhXnCYvHpOuBtT6OPJEna4CzUSJIkAJKcB5wEjgPnj636FHBXVe1slwbdPcDuTvC/M3uf1x43AX8Z3TtnwLgjT40tfxX4UlX9IMkCsPcZ7nPkH+3xJFM+Y1XVAeDASgIleQ3wLeDjc+YkSZI2GC99kiRJJDmHxUt+vlZVNbF6C/DHtvyuJUIcAq5qsRaAx6rqb8DPaDNCklzO4iU9AH8GtraZN6cDbwRofR5JcmXrk1a0mPRT4O1tmzfMiruE8XFdPdb+BPDCyY2r6q/A42P3n3kHcM/kdgM5H3hrVf1uleJLkqROWaiRJOnU9fzR13MDdwC3sXivmUmfAz6T5ChLz8bdC1yY5Biwn/8WPvYBl7cb/F4J/Al4oqr+BXwSuB+4ncX74IxcBbw7yQPAg8Cbp+xvH3BZy/0K4A8AM+JOy/lgkiPAY2PtPwR2jm4mPNHnauDzbZzb274GV1U3VdVDqxFbkiT1Lf//TzNJkqRhtFktJ6vqRJLXA9fNcVmTJEnSs573qJEkSavpXOA7STYB/wTeu875SJIkdc0ZNZIkSZIkSZ3wHjWSJEmSJEmdsFAjSZIkSZLUCQs1kiRJkiRJnbBQI0mSJEmS1AkLNZIkSZIkSZ34NwHPgzlr33A7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAAApCAYAAABtNM/XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFnklEQVR4nO3dX4gd5RnH8e8vjdqCNbWaFEFCUIoVwUYUaUMiexUQWkqselFRC60lF4pKg4ZCTaLQptY/QaVK6U1SKGpEpX9QVKw21rYhIZpWsF74D4Q2CLamIm0Tnl7se/R4ejYbdzd7ZrPfz82ZfWfeZ57ZMzN7ePad96SqkCRJkiRJ0ugtGHUCkiRJkiRJGmehRpIkSZIkqSMs1EiSJEmSJHWEhRpJkiRJkqSOsFAjSZIkSZLUEQsPtXL9q+un/JVQm2/bN9WurF+3ZMp9NbdM5zyZj6ZzbUz3d+11OXvm43Xh+TW7Rvk3elTn9yjznqv3bu9Fs2uunmPTMVfv/b5X88NcvQf6Xn08I73vn7Y5E61zRI0kSdJRaD5+WJck6WhgoUaSJEmSJKkjLNRIkiRJkiR1hIUaSZIkSZKkjrBQI0mSJEmS1BEWaiRJkiRJkjrCQo0kSZIkSVJHWKiRJEmSJEnqCAs1kiRJkiRJHWGhRpIkSZIkqSMs1EiSJEmSJHWEhRpJkiRJkqSOsFAjSZJ0FNp8275RpyBJkqYgVTXqHCRJkiRJkoQjaiRJkiRJkjrDQo0kSZIkSVJHWKiRJEmSJEnqCAs1kiRJkiRJHWGhRpKkeSrJwSQvJHkpyYtJvptkQVt3XpK7Juk/luTXs5PtoSV5PcnJMxRrLMmKvp/XJrliJmJLkiRNZuGoE5AkSSPzflUtB0iyBPgFcAKwoap2AbtGmdyRlGRhVR2YYPUY8C/geYCqum+28pIkSXJEjSRJoqr2Ad8Brs64D0bLJDk/yR+S7EnyfJIzBvsn+WySR5PsTfLHJGe39sVJnmyjdn6W5I0kJydZluQvff3XJdnYlk9P8niS3Ul2JPnCkP2dlOSJXlwgrf1QcZ9JsiXJLuDaJF9N8qd2XE8l+VySZcBa4Po22mhVko1J1rUYy9vx7U3ySJIT+2L/KMnOJK8kWTWd9yPJyiQnTSeGJEmamyzUSJIkAKrqVeATwJKBVS8Dq6rqHOAm4AdDum8C9lTV2cD3gG2tfQPwdFWdBTwELD2MVH4KXFNV5wLrgJ8M2WYD8FyL+8hhxgU4tqrOq6rbgeeAL7Xjuh+4oapeB+4D7qyq5VW1Y6D/NuDGdpx/bnn0LKyq84HrBtqn4kTgMYs1kiTNPz76JEmSJrMI2Jrk80ABxwzZZiXwdYCqerqNeDmhta9p7Y8needQO0pyPLAC2J6k13zckE0vAC5qcX8zWdw+D/Qtnwo8kOQU4FjgtUlyWwR8pqqebU1bge19mzzcXncDy4b0vw749mHmCePFp3uBSz9GH0mSNMdZqJEkSQAkOQ04COwDzuxbdQvw26pa0x4NemYGdneAj47s/WR7XQD8ozd3zgzG7Xmvb/lu4I6q+mWSMWDjFPfZ8+/2epAhn7Gqaguw5XACJfki8HPg+9PMSZIkzTE++iRJkkiymPFHfu6pqhpYvQh4qy1/c4IQO4DLWqwx4O2qehf4PW1ESJLVjD/SA/B3YEkbeXMc8BWA1ue1JJe0PmlFi0G/A77RtrlwsrgT6D+uK/va9wOfHty4qv4JvNM3/8zlwLOD282QM4GLq+qvRyi+JEnqKAs1kiTNX5/qfT038BTwBONzzQy6Ffhhkj1MPBp3I3Bukr3AZj4sfGwCVrcJfi8B/gbsr6r/AjcDO4EnGZ8Hp+cy4FtJXgReAr42ZH+bgAta7hcBbwJMEndYztuT7Abe7mv/FbCmN5nwQJ8rgR+341ze9jXjqur+qnrlSMSWJEndlv//p5kkSdLMaKNaDlbVgSRfBu6dxmNNkiRJRz3nqJEkSUfSUuDBJAuA/wBXjTgfSZKkTnNEjSRJkiRJUkc4R40kSZIkSVJHWKiRJEmSJEnqCAs1kiRJkiRJHWGhRpIkSZIkqSMs1EiSJEmSJHXE/wD4+lk52QYSCAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x18 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzO51lx3GuEN"
      },
      "source": [
        "#### 6.2.3 Sentiment Patterns of Podcast Dialogues in General"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibLmv-oh6WT0"
      },
      "source": [
        "# TODO: General patterns"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW1RnpkUKJ4_"
      },
      "source": [
        "Below you can see the aggregrated sentiment gradient for all podcast episodes in the dataset. Below the gradient, a graph is shown that show the gradient of the sentiment as well, where you can see that the start and end of the dialogue is positive, and most discussion and negative talks occur in the middle of the dialogue.\n",
        "\n",
        "First the data needs to be scaled using the function described in the Section 5.5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-ZOJYkJ-LIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd5f189-c2b6-472f-e622-6eea9c5e17f0"
      },
      "source": [
        "# scale data\n",
        "scaled_data = scale_data(data)\n",
        "\n",
        "# replace 0.0 values with -1.0\n",
        "scaled_data[scaled_data == 0.0] = -1.0\n",
        "print('\\nData successfully scaled!')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36318it [00:08, 4200.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Data successfully scaled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF38fw-73c-o"
      },
      "source": [
        "Then, using the scaled data, the aggregrated sentiment gradient can be visualized below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7O-PcwAKbMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "67b6ba5f-ffdd-47e8-b4e9-955ed0bd1243"
      },
      "source": [
        "# total sentiment gradient \n",
        "summed_scaled_data = np.sum(scaled_data, axis=0)\n",
        "summed_scaled_data = summed_scaled_data / max(summed_scaled_data)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,2))\n",
        "sns = seaborn.heatmap([summed_scaled_data], cmap=\"RdYlGn\", square=False, vmin=0, vmax=1, xticklabels=False, yticklabels=False, cbar=True,  cbar_kws={'label': 'Normalized aggregrated sentiment'})\n",
        "plt.xlabel('Dialogue duration ⟶')\n",
        "plt.show()\n",
        "\n",
        "x = list(range(len(summed_scaled_data)))\n",
        "plt.plot(x, summed_scaled_data)\n",
        "plt.ylabel('Normalized aggregrated sentiment')\n",
        "plt.xlabel('Dialogue duration ⟶')\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x144 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkc1CG8QAUE0"
      },
      "source": [
        "## 7 Findings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZgaK2yV7AXJ"
      },
      "source": [
        "### 7.1 Interpretation\n",
        "\n",
        "- TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwka5f-f7DgR"
      },
      "source": [
        "### 7.2 Discussion\n",
        "The one area that could have been most improved upon during this research was the labeled dataset. Due to time constraints, each utterance within this dataset was labeled by only one of three persons. While many of the utterances had a very clear sentiment, there were also cases where it wasn’t very obvious if the sentiment was more positive or negative. Having all utterances labeled by three persons and then deciding by majority vote would have lead to more accurate labels.\n",
        "\n",
        "Also, while 3012 labeled utterances were certainly enough to make the BERT model learn a certain sense of sentiment in dialogue utterance, having a larger labeled dataset would probably have given better performance in the metrics, especially a better recall.\n",
        "\n",
        "As an improvement for the K-means method, improvements could include creating a system that automatically appoints the cluster index, and using pre-trained Word2Vec models, as the dataset that is currently being used does not have 100% accurate transcripts, leading to a lot of lost vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrhixITSAV-x"
      },
      "source": [
        "## 8 Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJtMAvlB_bSj"
      },
      "source": [
        "### 8.1 Summary\n",
        "- TODO: Samenvatting + conclusions (inclusief beantwoorden RQs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1UzJQ8e_JT1"
      },
      "source": [
        "### 8.2 Future Work\n",
        "The performance of the used methods, especially those of the DistilBERT Classifier, show that it is certainly possible to reasonably accurately judge the sentiments of utterances within podcast transcripts. To expand on these findings, much more research in the field of sentiment analysis can be done.\n",
        "\n",
        "One suggestion for future research is to perform sentiment analysis on written texts other than podcast transcripts. While the Spotify Podcast Dataset contains a very large amount of different podcasts with wildly varying topics and speakers (and speaker styles), all transcripts that were used were still dialogues. Applying these methods to either monologues or texts with more than two speakers might give interesting results.\n",
        "\n",
        "Another idea for future research is applying sentiment analysis to speech rather than text. Obtaining a sentiment score using features such as pitch, volume and speech rate is a slightly different challenge from what was done here. Moreover, combining speech sentiment analysis with the text sentiment analysis could be a powerful combination. This could also very well be done with the Spotify Podcast Dataset, but was beyond the scope of this project. \n",
        "\n",
        "A third and final idea for future research is an extension on the research performed here, namely to see if the sentiment of one speaker throughout a dialogue influences the sentiment of the other speaker. Say one speaker is very positive about a certain subject and one starts off very negatively towards that subject, it would be very interesting to see how frequently it occurs that one of the speakers changes his or her sentiment throughout the dialogue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uhr1YE3AYJb"
      },
      "source": [
        "## References\n",
        "\n"
      ]
    }
  ]
}