{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLDO5_Lj4jlD"
   },
   "source": [
    "# Predicting Profile Features Based on Dialogue\n",
    "####  Language & Speech & Dialogue Processing Project\n",
    "##### Sam Titarsolej, Ying Liem, Selina Khan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyrZy6TtW1AV",
    "outputId": "e86e8b59-078e-4d24-9b19-e94ddebae467"
   },
   "outputs": [],
   "source": [
    "# # Colab specific drive mounting\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "# os.chdir(\"/content/drive/MyDrive/LSDP/Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73Qq56qcYe9e",
    "outputId": "818cf217-54b9-425c-9466-a5abff01dc9c"
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext\n",
    "# !pip install transformers\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DzqUiN0qVEXW"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import data_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Imports for the age & gender model\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Imports for the personalities model\n",
    "import personalities.configuration as config\n",
    "from personalities.training import train_persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4F6PFZU5m_4"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Dialogue is rich in information and essential for human conversation. In a dialogue, one can convey pieces of info they want their conversation partner to know. For example, plans for tomorrow, newest updates about their lives, etc. However, dialogue can also be used to retrieve underlying information about the conversers. Research suggests that characteristics such as gender[[1]](https://journals.sagepub.com/doi/10.1177/0023830914549084), age[[2]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3783449/) and personality[[2]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3783449/) can influence one’s language usage. Moreover, there's a trend in how such profile features influence language use across feature categories. The aim for this project is to use existing models to propose a method to extract various character traits from dialogue, rather than developing a perfectly functioning model.\n",
    "\n",
    "Our research question is hereby proposed as follows: “to what extent can dialogue be used to form a profile of a person?”. We aim to answer this question using personas from movies and TV shows, since a lot of data is available in the form of dialogues and profile features. Moreover, this research will focus on the profile features gender, age and personality, resulting in the following subquestions:\n",
    "\n",
    "1.   “To what extent can dialogue be used to predict the gender of a TV show or movie character?”\n",
    "2.   “To what extent can dialogue be used to predict the age of a TV show or movie character?”\n",
    "3. “To what extent can dialogue be used to predict the personality of a TV show or movie character?”\n",
    "\n",
    "To illustrate the research questions, in the TV-show 'Brooklyn 99', the main character Jake Peralta is an adult male with a quirky personality. By merely analysing the transcript of the show, one could guess Jake's profile features. Take his usage of the word 'bro', which is more commonly used by men. Moreover, he uses words that would normally not be included in a child's vocabulary and doesn't use old-fashioned words that could be seen in the vocabulary of elderly. Based on such observations, one could make an estimation that Jake is an adult. Lastly, a lot of jokes can be found in Jake's dialogue, which could show that he has a quirky personality. \\\\\n",
    "However, trends between profile features and dialogue aren't concrete and certain. There are females that also use 'bro' to call their male friend. Also, some children have a much broader vocabulary, whereas not all elderly use old-fashioned words and might even know and use some internet slang. And of course, personalities don't have black and white definitions; you could describe someone as quirky, but that doesn't necessarily mean he/she makes a lot of jokes. Nevertheless, there could be some general trends in language use across profile features that would work for most people. \n",
    "Therefore, we will investigate to what extent dialogue can be used to predict gender, age and personality of a TV show or movie character. <br><br>\n",
    "\n",
    "\n",
    "\n",
    "### Related Literature\n",
    "\n",
    "Quite some research has already been done in the attempt to extract specific features from dialogue. There are many published papers and articles proposing methods to determine a person’s gender based on spoken dialogues. This includes both audio-based approaches[[3]](http://www.cs.columbia.edu/~sarahita/papers/speech_prosody16.pdf)[[4]](https://ieeexplore.ieee.org/document/7342709)[[5]](https://iranjournals.nlai.ir/bitstream/handle/123456789/621435/50D7B725BB44A32A9317C554F68ADC2D.pdf?sequence=-1) and textual approaches[[6]](https://www.researchgate.net/publication/306093567_Gender-Distinguishing_Features_in_Film_Dialogue)[[7]](https://www.researchgate.net/publication/332017320_Gender_Classification_Using_Sentiment_Analysis_and_Deep_Learning_in_a_Health_Web_Forum)[[9]](https://iranjournals.nlai.ir/bitstream/handle/123456789/621435/50D7B725BB44A32A9317C554F68ADC2D.pdf?sequence=-1). Age group classification of a person based on spoken dialogues have also been researched to some extent[[8]](https://www.aclweb.org/anthology/E17-2030.pdf). Research in age categorization involves more audi-based approaches[[9]](https://iranjournals.nlai.ir/bitstream/handle/123456789/621435/50D7B725BB44A32A9317C554F68ADC2D.pdf?sequence=-1), as opposed to a textual approach we aim to research. Jiang et al.[[10]](https://arxiv.org/abs/1911.09304) have researched text-based classification of personality, and will be of great inspiration to us in our research. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHeDE-Tw6Xd5"
   },
   "source": [
    "## Experimental Setup\n",
    "We present an approach for automatic age, gender and personality classification. The gender and age approaches use a pre-trained contextual embedding model (‘DistilBERT’) and a logistic regression model. For predicting personality traits, a bidirectional LSTM with attention mechanisms is proposed.\n",
    "\n",
    "### Profile features\n",
    "As mentioned earlier, the profile features we focused on are gender, age and personality. While acknowledging that there are more than two genders, we will stick with two classes within the scope of this project: male and female. Age has a much wider range of possible values, therefore we decided to create age categories to make classification easier and more logical. The categories we settled on are ‘kid (0-9)', 'teen (10-19)', 'YA (20-35)', 'adult (36-50)' and 'elderly (50+)'. For personality, we will be using the big five personality traits, a widely used and accepeted taxonomy of five personality traits. The traits are: agreeableness, conscientiousness, extroversion, openess and neuroticism.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "To perform this investigation we used three dialogue datasets, namely from the cartoon ‘South Park’, the convokit corpus of the TV-show ‘Friends’ and the convokit ‘Cornell Movie-Dialogs Corpus’. Furthermore, we used the Wiki Fandom pages of the shows ‘South Park’ and ‘Friends’ to obtain gender and age labels for the characters using a web-scraping method. The movie dataset already included gender labels, however ages of the characters had to be manually annotated. For the personality labels, we were greatly inspired by Jiang et al.[[10]](https://arxiv.org/abs/1911.09304) and used their annotated Friends personalities, which they obtained through crowdsourcing, for our own research. The training and testing of the personality classification model was thereby limited to usage of only the Friends dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "2C3zxAILq9O6",
    "outputId": "6905ace3-f603-4844-c691-2edc7b1f5b7c"
   },
   "outputs": [],
   "source": [
    "# Load stop words and swear words files.\n",
    "# From: https://gist.github.com/sebleier/554280\n",
    "with open('data/stop_words.txt', 'r') as f:\n",
    "    stop_words = f.read().split('\\n')\n",
    "# From: https://www.cs.cmu.edu/~biglou/resources/bad-words.txt\n",
    "with open('data/swear_words.txt', 'r') as f:\n",
    "    swear_words = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9K1PoaVw1v-"
   },
   "source": [
    "Four functions used for statistical analysis are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g9qvJjyFVZQC"
   },
   "outputs": [],
   "source": [
    "def simplify(x):\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    x = x.lower()\n",
    "    x = x.split()\n",
    "    return x\n",
    "\n",
    "# Calculate word frequency for each specified character\n",
    "def word_freq(characters, df):\n",
    "    axs = tuple(['ax' + str(i) for i in range(len(characters))])    \n",
    "    wordfreqs = []\n",
    "    \n",
    "    for character in characters:\n",
    "        df_char = df[df['speaker'] == character]['text'].apply(simplify)\n",
    "        char = [item for sublist in df_char.tolist() for item in sublist]\n",
    "        char = [word for word in char if word not in stop_words]\n",
    "        counts = Counter(char).most_common(10)\n",
    "        wordfreqs.append(dict((x, y) for x, y in counts))\n",
    "        \n",
    "    fig, axs = plt.subplots(len(axs), figsize=(10, 20))\n",
    "    fig.suptitle('Word frequency per character')\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.set_title(characters[i])\n",
    "        ax.bar(wordfreqs[i].keys(), wordfreqs[i].values())\n",
    "\n",
    "# Calculate average utterance length for each specified character\n",
    "def seq_length(characters, df):\n",
    "    avgs = []\n",
    "    \n",
    "    for i, char in enumerate(characters):\n",
    "        seqs = df[df['speaker'] == char]['length'].tolist()\n",
    "        avg_len = sum(seqs)/len(seqs)\n",
    "        avgs.append(str(char + ' has an average utterance length of ' + str(avg_len)))\n",
    "    return avgs\n",
    "\n",
    "# Calculate the swearword-rate of each specified character\n",
    "def swearing(characters, df):\n",
    "    result = []\n",
    "    \n",
    "    for char in characters:\n",
    "        df_char = df[df['speaker'] == char]['text'].apply(simplify)\n",
    "        words = [item for sublist in df_char.tolist() for item in sublist]\n",
    "        wordlist = [word for word in words if word not in stop_words]\n",
    "\n",
    "        sw_words = 0\n",
    "        swears = []\n",
    "        for word in wordlist:\n",
    "            if word in swear_words:\n",
    "                sw_words += 1\n",
    "        perc = round(sw_words / len(wordlist) * 100)\n",
    "        result.append(str(char + ' speaks ' + str(len(wordlist)) + ' words, of which ' \n",
    "                          + str(sw_words) + ' are swear words. This is ' + str(perc) + '%'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2PMUCzUzVyI"
   },
   "source": [
    "As mentioned before, we used the South Park and Friends Wiki fandom pages to obtain gender and age labels for all the characters. This was done using web-scraping, which was enabled by a clear structure in the fandom pages. This task is defined in the function '*label*'. As these labels are essential for training the prediction models, the characters with no labels will be excluded from the dataset. <br>\n",
    "\n",
    "<u>Gender</u>: The extraction of gender labels was relatively simple. To stick to the selected gender categories, characters with different or multiple genders are labelled with 'None' (no label) to also be excluded from the dataset. <br>\n",
    "\n",
    "<u>Age</u>: The South Park characters remain the same age throughout the whole show, which if known was stated on the Wiki Fandom pages. Sometimes an estimation was given, e.g. '10-11'. For simplicity and ease of computation, only the first age was taken as the actual age. For Friends, the characters age around a decade throughout the whole series. Therefore, the Wiki fandom pages only stated the birth year. We decided to take about the median age. It can be noted that only the birth years of the main characters were available. Nevertheless, this corresponds with our choice to only include the characters with significant or sufficient amount of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nryvBPFZrBOF"
   },
   "outputs": [],
   "source": [
    "# Define the age categories\n",
    "def age_category(age):\n",
    "    if 0 <= age <= 9:\n",
    "        category = 'kid (0-9)'\n",
    "    elif 10 <= age <= 19:\n",
    "        category = 'teen (10-19)'\n",
    "    elif 20 <= age <= 35:\n",
    "        category = 'young adult (20-35)'\n",
    "    elif 36 <= age <= 50:\n",
    "        category = 'adult (36-50)'\n",
    "    else:\n",
    "        category = 'elderly (50+)'\n",
    "    return category\n",
    "\n",
    "# Use web-scraping to find the gender and age of the TV-show characters\n",
    "def label(show, characters):\n",
    "    genders = defaultdict(str)\n",
    "    ages = defaultdict(str)\n",
    "    \n",
    "    cont_class = 'pi-item pi-data pi-item-spacing pi-border-color'\n",
    "    hold_class = 'pi-data-value pi-font'\n",
    "    \n",
    "    for character in tqdm(characters):        \n",
    "        try:\n",
    "            c_name = character.replace(' ', '_')\n",
    "            url = 'https://' + show + '.fandom.com/wiki/' + c_name\n",
    "            soup = BeautifulSoup(requests.get(url).content, 'lxml')\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(e.code)\n",
    "            if e.code == 404:              # Character's profile features are unkown or not available\n",
    "                genders[character], ages[character] = None, None\n",
    "                print(f'no info for {character}')\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "            \n",
    "        # Extract gender\n",
    "        gender_div = soup.find('div', { 'class': cont_class, 'data-source': 'gender' })\n",
    "        if gender_div is not None:\n",
    "            gender = gender_div.find('div', { 'class': hold_class }).get_text()\n",
    "            if (gender == 'Male') or (gender == 'Female'):\n",
    "                genders[character] = gender\n",
    "\n",
    "        # Extract age\n",
    "        if show == 'southpark':\n",
    "            age_div = soup.find('div', { 'class': cont_class, 'data-source' : 'age'})\n",
    "            if age_div is not None:\n",
    "                age = age_div.find('div', { 'class': hold_class }).get_text()\n",
    "                number = re.findall(\"[\\dA-Za-z]*\", age)[0]\n",
    "                if number.isdigit():\n",
    "                    age = age.split('[')[0]\n",
    "                    age = age.split('-')[0]\n",
    "                    ages[character] = age_category(int(age))\n",
    "        else:\n",
    "            dob_div = soup.find('div', { 'class': cont_class, 'data-source': 'dob' })\n",
    "            if dob_div is not None:\n",
    "                dob = dob_div.find('div', { 'class': hold_class }).get_text()\n",
    "                year = int(re.match(r'.*([1-3][0-9]{3})', dob).group(1))\n",
    "                age = 1998 - year\n",
    "                ages[character] = age_category(int(age))\n",
    "                \n",
    "    return genders, ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Lh6BuC6uqY"
   },
   "source": [
    "#### South Park dataset\n",
    "The South-Park dataset spans over 10 seasons specifying the season number, utterance and character description for each row in the dataset. We only keep the character name and dialogue line (utterance) as the other aspects are irrelevant to the task at hand. Some columns are renamed, in order to let the dataframes of the 3 datasets match. Moreover, only the characters with a significant amount of dialogue lines are included in the dataset and labelled. <br> \n",
    "We also tokenized and further cleaned and processed the lines, producing the 'Tokenized' column in the dataframe. After running this step, we saved the dataframe in a .csv file. We excluded the function to process the lines in this notebook and instead load the dataframe from the .csv file. Moreover, we also computed the lengths of the tokens in the 'Tokenized' column, to be used for statistical analysis. This function is also excluded in this notebook. The corpus was also run through the function above, *label*, but the actual running is excluded in this notebook. We excluded these functions and executions to limit the code to only that relevant to the main task of this project and to restrict computational time/runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NszTORca6ttV"
   },
   "outputs": [],
   "source": [
    "def load_southpark(in_file):\n",
    "    # Load input file\n",
    "    df = pd.read_csv(in_file)\n",
    "    df = df[['Character', 'Line']]\n",
    "    df = df.rename(columns={ 'Character': 'speaker', 'Line': 'text' })\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('\\n', ''))\n",
    "    \n",
    "    significant_characters = df['speaker'].value_counts()[:30]\n",
    "    genders, ages = label('southpark', significant_characters.index)\n",
    "    \n",
    "    df['source'] = 'South Park'\n",
    "    df['gender'] = df['speaker'].apply(lambda x: genders[x])\n",
    "    df['age'] = df['speaker'].apply(lambda x: ages[x])\n",
    "\n",
    "    df['length'] = df['text'].apply(lambda x: x.count(' ') + 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RCX70yLBrD83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:05<00:00,  5.22it/s]\n"
     ]
    }
   ],
   "source": [
    "south_park = load_southpark('data/southpark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fHCpqbySrJsf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_freq(['Butters', 'Kyle', 'Cartman', 'Kenny', 'Stan'], south_park)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "W2DKfNhLrLVn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Butters has an average utterance length of 11.620292083013068',\n",
       " 'Kyle has an average utterance length of 9.190449359064656',\n",
       " 'Cartman has an average utterance length of 13.69500716185799',\n",
       " 'Kenny has an average utterance length of 5.009080590238366',\n",
       " 'Stan has an average utterance length of 9.195703125']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length(['Butters', 'Kyle', 'Cartman', 'Kenny', 'Stan'], south_park)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ovRoIM1MrMkv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Butters speaks 13990 words, of which 637 are swear words. This is 5%',\n",
       " 'Kyle speaks 30234 words, of which 2019 are swear words. This is 7%',\n",
       " 'Cartman speaks 63752 words, of which 4432 are swear words. This is 7%',\n",
       " 'Kenny speaks 1990 words, of which 227 are swear words. This is 11%',\n",
       " 'Stan speaks 32874 words, of which 1970 are swear words. This is 6%']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swearing(['Butters', 'Kyle', 'Cartman', 'Kenny', 'Stan'], south_park)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bM1TkGvX7iS_"
   },
   "source": [
    "#### Friends Dataset\n",
    "\n",
    "The Friends corpus also spans 10 seasons and includes utterance id, utterance, to who the utterance is spoken to, the tokens (tokenized utterance/line), the season and episode information, a big5 personality label, etc. Similar to the South Park dataset, only the relevant columns were kept and similar processing steps such as labelling were executed outside of this notebook. The only difference is that tokenization and cleaning wasn't necessary as it was already included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cTOA_G1h4fYC"
   },
   "outputs": [],
   "source": [
    "def load_friends(in_file):\n",
    "    with open(in_file) as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "    # Load json lines and keep columns of interest\n",
    "    df = pd.DataFrame([json.loads(line) for line in content])\n",
    "    df = df[['speaker', 'text']]\n",
    "    df = df[df['speaker'] != 'TRANSCRIPT_NOTE']\n",
    "    \n",
    "    significant_characters = df['speaker'].value_counts()[:30]\n",
    "    genders, ages = label('friends', significant_characters.index)\n",
    "    \n",
    "    df['source'] = 'Friends'\n",
    "    df['gender'] = df['speaker'].apply(lambda x: genders[x])\n",
    "    df['age'] = df['speaker'].apply(lambda x: ages[x])\n",
    "\n",
    "    df['length'] = df['text'].apply(lambda x: x.count(' ') + 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hbkbu1e9rO8M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  6.59it/s]\n"
     ]
    }
   ],
   "source": [
    "friends = load_friends('data/friends.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nH3jgTW3rPfC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monica Geller has an average utterance length of 9.778771475641328',\n",
       " 'Rachel Green has an average utterance length of 10.466938163112207',\n",
       " 'Phoebe Buffay has an average utterance length of 10.82239023743202',\n",
       " 'Joey Tribbiani has an average utterance length of 10.534023128423616',\n",
       " 'Chandler Bing has an average utterance length of 10.135971055088703',\n",
       " 'Ross Geller has an average utterance length of 10.43193974456937']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length(['Monica Geller', 'Rachel Green', 'Phoebe Buffay', 'Joey Tribbiani', 'Chandler Bing', 'Ross Geller'], friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QXR4DTU0rQmh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monica Geller speaks 36412 words, of which 967 are swear words. This is 3%',\n",
       " 'Rachel Green speaks 41765 words, of which 1161 are swear words. This is 3%',\n",
       " 'Phoebe Buffay speaks 35690 words, of which 1008 are swear words. This is 3%',\n",
       " 'Joey Tribbiani speaks 38091 words, of which 894 are swear words. This is 2%',\n",
       " 'Chandler Bing speaks 37933 words, of which 949 are swear words. This is 3%',\n",
       " 'Ross Geller speaks 42095 words, of which 857 are swear words. This is 2%']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swearing(['Monica Geller', 'Rachel Green', 'Phoebe Buffay', 'Joey Tribbiani', 'Chandler Bing', 'Ross Geller'], friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP93Mxpy8MwM"
   },
   "source": [
    "#### Movies Dataset\n",
    "This dataset was composed of multiple movies and hand annotated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZdL1i5aO8QxY"
   },
   "outputs": [],
   "source": [
    "def load_movies(lines_file, meta_file):\n",
    "    # Load dataframes\n",
    "    kwargs = { 'delimiter': '\\ \\+\\+\\+\\$\\+\\+\\+\\ ', 'encoding' : 'latin-1', 'header' : None }\n",
    "    line_df = pd.read_csv(lines_file, engine='python', **kwargs)\n",
    "    meta_df = pd.read_csv(meta_file, engine='python', **kwargs)\n",
    "\n",
    "    # Set column names\n",
    "    line_df.columns = ['line_id','char_id','movie_id','char_name','text']\n",
    "    meta_df.columns = ['char_id','char_name','movie_id', 'movie_name','gender','credits_pos']\n",
    "\n",
    "    # Fromalize meta dataframe\n",
    "    meta_df['gender'] = meta_df['gender'].str.strip()\n",
    "    meta_df = meta_df[meta_df['gender'] != '?']\n",
    "    meta_df['gender'] = meta_df['gender'].apply(lambda x: 'Male' if x in ['m', 'M'] else 'Female') \n",
    "\n",
    "    # Merge meta and lines df's on movie_id and char_name\n",
    "    df = pd.merge(line_df, meta_df, how='inner', on=['movie_id', 'char_name'],\n",
    "                  left_index=False, right_index=False, sort=True, copy=False,\n",
    "                  indicator=False).drop('char_id_y', axis=1)\n",
    "    df = df.rename(columns={ 'char_id_x': 'char_id' })\n",
    "\n",
    "    # Cleanup final df\n",
    "    df['age'] = df['char_id'].apply(lambda x: data_utils.MOVIE_CHAR_TO_AGE.get(x))\n",
    "    df = df[['movie_name', 'char_name', 'text', 'age', 'gender']]\n",
    "    df = df.rename(columns={ 'movie_name': 'source', 'char_name': 'speaker' })\n",
    "\n",
    "    df['length'] = df['text'].apply(lambda x: x.count(' ') + 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pUHXH1r5rWAP"
   },
   "outputs": [],
   "source": [
    "movies = load_movies('data/movie_lines.txt', 'data/movie_meta.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CKSD8XAarWsK"
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([movies, friends, south_park])\n",
    "full_df = full_df[full_df['length'] < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NUJlT3T8_6o"
   },
   "source": [
    "### Approaches\n",
    "In this section, we will elaborate on the models we have used, after which we initialize and train our classification models on the datasets. \n",
    "\n",
    "#### Models used\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a method of pre-training language representations. This means that we train a general-purpose model which is able to understand the language on a text corpus (In our case, the datasets mentioned earlier). The pre-trained model is thereafter used for NLP tasks, such as text classification. We have decided to use BERT since it is a state-of-the-art encoder which has shown to outperform previous methods. BERT’s key technical innovation is the application of a bi-directional Transformer (an attention model) on language modelling tasks. This model has a better sense of context within a  language and has shown outstanding results for NLP-tasks[9]. Moreover, its code is open-source and user-friendly, making it possible to actually use and implement it.\n",
    "\n",
    "We used the smaller version of Google’s BERT model, called ‘DistilBERT’ to process the input dialogue lines and extract information from it. A smaller version was used since we had limited computational power. The information is encoded in the form of a vector/matrix that can be seen as the embedding of the input. This vector is used by the scikit Logistic Regression model to actually do the classification by predicting the labels. We used a pre-trained DistilBERT model that was trained on the English language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iKf1fDqfimlw"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load BERT\n",
    "bert_model = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "bert_tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "839Pm4Ox7WSH"
   },
   "source": [
    "The get_bert_features() function does the following: encoding the dialogue lines in a desired-format for BERT, padding and masking the input and finally returning the features. The BERT tokenizer, besides encoding the sentences, also adds special tokens, which are needed for classification, at the beginning and end of a sequence. Next, the tokenizer replaces the tokens with corresponding ids from the embedding table. This results in a list of lists or vectors of uneven lengths. In order to be able to give the input to DistilBERT in one go, we need to make it a suitable input matrix. To do so, the vectors need to be padded to equal sizes. The shorter sentences are padded with an id of 0. Nevertheless, we don’t want DistilBERT to read those zeroes, hence we mask them to let BERT know that they should be ignored. Finally, the input matrix can be given to DistilBERT. The processed results are given to ‘last_hidden_states’. The features we want is only a slice of the full output, corresponding to the complete sentence embeddings. \n",
    "\n",
    "The get_bert_features() function was used on both the age and gender training and test sets to obtain age and gender features as input for the LR models. It should be noted that the padding step of the get_bert_features() function results in a sparse matrix, which can take a lot of unnecessary computing power. For example, if in the dataset, there’s one sentence that’s 200 tokens long, whilst most lines only consist of 50 tokens, then the resulting matrix will have a lot of insignificant zeros. To limit the amount of zeros in the input matrix, we constrain the length of sentences given to the get_bert_features() function.\n",
    "The features and corresponding labels were first again split into training and test features with a 3:1 ratio. Here, the test features are used to test the accuracy of the LR model. We used separate LR models for age and gender, because they are 2 separate predictions. The models were trained using the train features and tested with the test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bXT6LLbtreGS"
   },
   "outputs": [],
   "source": [
    "def get_bert_features(batch):\n",
    "    encoded = batch['text'].apply(lambda x: bert_tokenizer.encode(x, add_special_tokens=True))\n",
    "    \n",
    "    # Apply zero-padding\n",
    "    max_len = max(len(x) for x in encoded.values)\n",
    "    padded = np.array([x + [0] * (max_len - len(x)) for x in encoded.values])\n",
    "\n",
    "    # Calculate attention mask\n",
    "    mask = np.where(padded != 0, 1, 0)\n",
    "    \n",
    "    # Create input tensors for BERT\n",
    "    X = torch.tensor(padded).to(device)\n",
    "    mask = torch.tensor(mask).to(device)\n",
    "    \n",
    "    # Forward input through model\n",
    "    with torch.no_grad():\n",
    "        y = bert_model(X, attention_mask=mask)\n",
    "    result = y[0][:, 0, :].cpu().numpy()\n",
    "    \n",
    "    # Clear CUDA memory\n",
    "    if device == 'cuda':\n",
    "        del X, mask, y\n",
    "        torch.cuda.empty_cache()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yV5wYUN9rfYr"
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lERw4Asorgo2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1459/1459 [12:51<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "full_df['features'] = None\n",
    "for i in tqdm(range(0, len(full_df), batch_size)):\n",
    "    features = get_bert_features(full_df[i:i + batch_size])\n",
    "    features_df = pd.DataFrame(data={ 'features': list(features) })\n",
    "    full_df.iloc[i:i + batch_size, -1] = pd.DataFrame(data={ 'features': list(features) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xmMubvUUriEB"
   },
   "outputs": [],
   "source": [
    "gen_df = full_df[(full_df['gender'].notnull()) & (full_df['gender'] != '')]\n",
    "age_df = full_df[(full_df['age'].notnull()) & (full_df['age'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GVY6ia6crjJq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      234229\n",
       "Female    101137\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_df['gender'].value_counts().sort_values().plot(kind='bar')\n",
    "gen_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "l4-BZC2Crk1Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "young adult (20-35)    53226\n",
       "teen (10-19)           29685\n",
       "adult (36-50)           6036\n",
       "kid (0-9)               1197\n",
       "elderly (50+)            408\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAFSCAYAAAAQBrOYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgsklEQVR4nO3debhcVZ3u8e8LYRBllBhoAiZgHBAFMQz3YouCQABbkBYEvZKLNPER7MZuvW3sa18cQNGnnegWFSUanBBRBCUa04hTK0MCGGSSyCBBhmgi0CJD8L1/7FWmcqhzTp2YU6uSej/PU8/Ztfauc35np3Le2muvvbZsExERg22D2gVERER9CYOIiEgYREREwiAiIkgYREQECYOIiAAm1C5gTW277baeMmVK7TIiItYZixYt+q3tiZ3WrbNhMGXKFBYuXFi7jIiIdYakO4dbl26iiIhIGERERMIgIiJIGEREBAmDiIggYRARESQMIiKChEFERLAOX3QWEdErU2ZfWrsEAO448/Bx+945MoiIiIRBREQkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQEXYaBpDskXS/pOkkLS9s2khZIurV83bq0S9JZkpZIWixpz7bvM7Nsf6ukmW3tLy7ff0l5rdb2LxoREcMby5HBy23vYXt6eT4buMz2NOCy8hzgUGBaecwCPglNeACnAfsAewOntQKkbHNS2+tmrPFvFBERY/aXdBMdAcwty3OBI9vaz3PjCmArSdsDhwALbC+3vQJYAMwo67awfYVtA+e1fa+IiOiBbsPAwPckLZI0q7RNsn1PWb4XmFSWdwDuanvt0tI2UvvSDu0REdEj3U5U9xLbd0t6BrBA0s3tK21bktd+easrQTQLYKeddhrvHxcRMTC6OjKwfXf5ej9wEU2f/32li4fy9f6y+d3Ajm0vn1zaRmqf3KG9Ux3n2J5ue/rEiRO7KT0iIrowahhIeqqkzVvLwMHAL4BLgNaIoJnAxWX5EuD4MqpoX+CB0p00HzhY0tblxPHBwPyy7kFJ+5ZRRMe3fa+IiOiBbrqJJgEXldGeE4Av2/6upKuBCySdCNwJHFO2nwccBiwBHgZOALC9XNL7gKvLdu+1vbwsnwx8HngK8J3yiIiIHhk1DGzfBuzeof13wIEd2g2cMsz3mgPM6dC+ENiti3ojImIc5ArkiIhIGERERMIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRAREYwhDCRtKOlaSd8uz6dKulLSEklflbRxad+kPF9S1k9p+x7vLO23SDqkrX1GaVsiafZa/P0iIqILYzkyOBW4qe35B4GP2n4WsAI4sbSfCKwo7R8t2yFpV+BY4PnADODsEjAbAp8ADgV2BY4r20ZERI90FQaSJgOHA58tzwUcAFxYNpkLHFmWjyjPKesPLNsfAZxv+1HbtwNLgL3LY4nt22w/Bpxfto2IiB7p9sjgY8A/A38qz58O/N72yvJ8KbBDWd4BuAugrH+gbP/n9iGvGa49IiJ6ZNQwkPRK4H7bi3pQz2i1zJK0UNLCZcuW1S4nImK90c2RwX7AqyTdQdOFcwDwcWArSRPKNpOBu8vy3cCOAGX9lsDv2tuHvGa49iexfY7t6banT5w4sYvSIyKiG6OGge132p5sewrNCeDv2349cDnwmrLZTODisnxJeU5Z/33bLu3HltFGU4FpwFXA1cC0Mjpp4/IzLlkrv11ERHRlwuibDOsdwPmSTgeuBc4t7ecCX5C0BFhO88cd2zdIugC4EVgJnGL7CQBJbwHmAxsCc2zf8BfUFRERYzSmMLD9A+AHZfk2mpFAQ7d5BDh6mNefAZzRoX0eMG8stURExNqTK5AjIiJhEBERCYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQURE0EUYSNpU0lWSfi7pBknvKe1TJV0paYmkr0rauLRvUp4vKeuntH2vd5b2WyQd0tY+o7QtkTR7HH7PiIgYQTdHBo8CB9jeHdgDmCFpX+CDwEdtPwtYAZxYtj8RWFHaP1q2Q9KuwLHA84EZwNmSNpS0IfAJ4FBgV+C4sm1ERPTIqGHgxn+XpxuVh4EDgAtL+1zgyLJ8RHlOWX+gJJX2820/avt2YAmwd3kssX2b7ceA88u2ERHRI12dMyif4K8D7gcWAL8Cfm97ZdlkKbBDWd4BuAugrH8AeHp7+5DXDNceERE90lUY2H7C9h7AZJpP8s8dz6KGI2mWpIWSFi5btqxGCRER66UJY9nY9u8lXQ78D2ArSRPKp//JwN1ls7uBHYGlkiYAWwK/a2tvaX/NcO1Df/45wDkA06dP91hqj4ixmTL70tolAHDHmYfXLmEgdDOaaKKkrcryU4CDgJuAy4HXlM1mAheX5UvKc8r679t2aT+2jDaaCkwDrgKuBqaV0Ukb05xkvmQt/G4REdGlbo4MtgfmllE/GwAX2P62pBuB8yWdDlwLnFu2Pxf4gqQlwHKaP+7YvkHSBcCNwErgFNtPAEh6CzAf2BCYY/uGtfYbRkTEqEYNA9uLgRd1aL+N5vzB0PZHgKOH+V5nAGd0aJ8HzOui3oiIGAe5AjkiIhIGERGRMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQEXYSBpB0lXS7pRkk3SDq1tG8jaYGkW8vXrUu7JJ0laYmkxZL2bPteM8v2t0qa2db+YknXl9ecJUnj8ctGRERn3RwZrATeZntXYF/gFEm7ArOBy2xPAy4rzwEOBaaVxyzgk9CEB3AasA+wN3BaK0DKNie1vW7GX/6rRUREt0YNA9v32L6mLD8E3ATsABwBzC2bzQWOLMtHAOe5cQWwlaTtgUOABbaX214BLABmlHVb2L7CtoHz2r5XRET0wJjOGUiaArwIuBKYZPuesupeYFJZ3gG4q+1lS0vbSO1LO7R3+vmzJC2UtHDZsmVjKT0iIkbQdRhIehrwdeCtth9sX1c+0Xst1/Ykts+xPd329IkTJ473j4uIGBhdhYGkjWiC4Eu2v1Ga7ytdPJSv95f2u4Ed214+ubSN1D65Q3tERPRIN6OJBJwL3GT7I22rLgFaI4JmAhe3tR9fRhXtCzxQupPmAwdL2rqcOD4YmF/WPShp3/Kzjm/7XhER0QMTuthmP+ANwPWSritt/wKcCVwg6UTgTuCYsm4ecBiwBHgYOAHA9nJJ7wOuLtu91/bysnwy8HngKcB3yiMiInpk1DCw/RNguHH/B3bY3sApw3yvOcCcDu0Lgd1GqyUiIsZHrkCOiIiEQUREJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQRdhIGmOpPsl/aKtbRtJCyTdWr5uXdol6SxJSyQtlrRn22tmlu1vlTSzrf3Fkq4vrzlLktb2LxkRESPr5sjg88CMIW2zgctsTwMuK88BDgWmlccs4JPQhAdwGrAPsDdwWitAyjYntb1u6M+KiIhxNmoY2P4RsHxI8xHA3LI8Fziyrf08N64AtpK0PXAIsMD2ctsrgAXAjLJuC9tX2DZwXtv3ioiIHlnTcwaTbN9Tlu8FJpXlHYC72rZbWtpGal/aob0jSbMkLZS0cNmyZWtYekREDPUXn0Aun+i9Fmrp5medY3u67ekTJ07sxY+MiBgIaxoG95UuHsrX+0v73cCObdtNLm0jtU/u0B4RET20pmFwCdAaETQTuLit/fgyqmhf4IHSnTQfOFjS1uXE8cHA/LLuQUn7llFEx7d9r4iI6JEJo20g6SvAy4BtJS2lGRV0JnCBpBOBO4FjyubzgMOAJcDDwAkAtpdLeh9wddnuvbZbJ6VPphmx9BTgO+URERE9NGoY2D5umFUHdtjWwCnDfJ85wJwO7QuB3UarIyIixk+uQI6IiIRBREQkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERdDEdRcQgmTL70tolAHDHmYfXLiEGTI4MIiIiYRAREQmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQEue1lkFs9RkQfHRlImiHpFklLJM2uXU9ExCDpizCQtCHwCeBQYFfgOEm71q0qImJw9Es30d7AEtu3AUg6HzgCuHG8fmC6RiIiVpHt2jUg6TXADNt/V56/AdjH9luGbDcLmFWePge4paeFPtm2wG8r19Avsi9Wyb5YJftilX7YF8+0PbHTin45MuiK7XOAc2rX0SJpoe3ptevoB9kXq2RfrJJ9sUq/74u+OGcA3A3s2PZ8cmmLiIge6JcwuBqYJmmqpI2BY4FLKtcUETEw+qKbyPZKSW8B5gMbAnNs31C5rG70TZdVH8i+WCX7YpXsi1X6el/0xQnkiIioq1+6iSIioqKEQUREJAwiIqJPTiCvKyQ9A9gP+Cvgj8AvgIW2/1S1sEokbQDsTtv+sH1/3ap6T9J04K9Z/X2xwPaKqoVVkH3RkLQp8EqevC8u7dfBMTmB3AVJLwdmA9sA1wL3A5sCzwZ2AS4EPmz7wWpF9pCkXYB3AK8AbgWWsWp/PAx8Gpi7voekpBOAvwduBxax+vtiP5r//P9q+9fViuyR7ItVJL2HJgh+wJP3xcvL8ttsL65VYyc5MujOYcBJnd7IkibQ/MMfBHy914VVcjrwSeBNHvJpohw9vQ54AzC3Qm29tBmwn+0/dlopaQ9gGrDe/wEk+6LdVbZPG2bdR8r/kZ16WVA3cmQQERE5MlgTkg6yvaB2HTVJehowg2YakSeAXwLfW9+7htqVo8ITgVfT9AtDM43KxcC5th+vVVsNpTv1b1n9PfFZ20uqFtZjkl7Y6gKStBFNl+reNF1lp9t+uGZ9w8mRwRqQdI3tPWvXUYukY4C3A4tp+kB/SjMy7QXA621fX7G8npH0FeD3NN1hS0vzZGAmsI3t11YqreckfQDYDrgMOJLm3MEvgZOB99v+Wr3qeqv974OkDwNPBz5Hs1+ebvv4iuUNK2GwBhIGWgzsa/thSdsCX7J9iKQXAp+y/T8rl9gTkn5p+9ljXbc+knS97ReU5QnAD23vJ2lr4Me2d6tbYe9Iutb2i8rydcBeth+XJODntl9YtcBhpJuoS5I+BxgQsJOkOa11tt9YrbA6RDNUDuAPwDMAbC+WtEW1qnpvuaSjga+3usfKcNujgYEaSgn8SdI2tpfTdJltCGB7RfkjOEi2lPRqmqPlTVrdhbYtqW8/fScMuvf5tuWXsP6PlBnJPOC7kn5Ec97gawCStqEJikFxLPBB4GxJK2h+9y2By8u6QfJ+4FpJv6S58dSbASRNBH5es7AKfgi8qixfIWmS7fskbUf9m9sMK91Ea2DQu4kAJB1Gc7/qn7dOppdPxRvZfrRqcRVIejqA7d/VrqWW8mFgZ5pb2P6+cjkxRgmDNSDpCtv71q6jn0h6pe1v166jJklTgRcBN9q+uXY9/ULScwdtf0jam6Zn6GpJu9IcQd9se17l0oaVMIi1YhCPliR90/aRZfkI4GM0V53uRzOC5vO1ausnkn5tu+8ushovkk4DDqXphl8A7EPTdXgQMN/2GRXLG1bCoEvlJNjewA6l6W6aKw2zA1l9BMWgGDJq5Kc0w2pvLyOsLrO9e90Ke0fSWcOtAmbaHpiBBZKuB/YANgHuBSbbflDSU4ArM5poHSbpYOBsmnl4Wvdmngw8S9LJtr9Xrbj+8abaBVTQ/kFggu3bAWz/VtLAXHxXnAC8Deh0vui4HtdS20rbTwAPS/pVa84y23/s5/dFwqA7HwdeYfuO9sbSRzwPeF6NomqS9FzgCNqOlCQ9ZPumimX12u6SHqT59LuJpO1t31Pu471h5dp67WqaWWt/OnSFpHf3vpyqHpO0WbnS+MWtRklbAn0bBukm6oKkW4Hn2V45pH1jmpOFz6pTWR2S3kHzae98Vr/y9ljgfNtn1qqtH0jaiub98rPatfRKGUn0SL9OtdBLkjbpNKKudB9u369X6CcMuiDpncAxNH/87irNO9L88bvA9gdq1VZDGUv+/KFz75RwvMH2tDqV1ZdRVatI2tP2NbXr6AeSZtk+p3YdI0kYdEnS8xjSLQJcYvvGelXVIelm4BDbdw5pfybNZHXPqVNZfYM4qmo42RerrAv7IucMulT6wgepP3wkbwUuK91nrSOlnYBnAW+pVVSfGKQrsEeTfbFK3++LHBl0QdIM298ty1sCH2bVlLT/aPu+mvXVUK42HjrU9uoyimJgSdrb9lW16+gHko60/c3adfQDSZNtLx19y3oSBl0YMiXtZ2nGDn8GOArYv3Xh0aCQ9DTb//2XbrOuk7QTcL/tR8p1KP8b2BO4EfjM0AEH67vyQWkGq39AmD+IU1NIOoRmyur2fXFx60NlP9qgdgHroOm232X7TtsfBabULqiCiyV9WNJLJT211ShpZ0knSppP80dhfTePVf+HzgQOB64E9gL6+mTh2ibpeOAa4GU0t8DcjOZeF4vKuoEh6WPAqTQT1n2oPH4I/IOkj1csbUQ5MuiCpKXAR2j6/U4BdmldeSxpcb9eUTieykR1r6eZemEb4HHgFuBSmrt83VuxvJ6QdKPtXcvyIpp561tTWf98wK5AvgXYZ+hRQLmfwZUDdm+HjveyKEePv+zX0XY5gdydzwCbl+W5wLbAsjIl7XW1iqqpTLjVt5Nu9chdkg6w/X3gDprhxne2ZjAdMGL1K7Jb/sQ6cPJ0LXtE0l62rx7SvhfwSI2CupEjg4g1JGlH4Dyaq40foLnPxXXAVsDbbV9WrbgekzQT+H/A91h9hNlBwPsGadI+SXsCn6T5ANk6abwjzXvkFNuLatU2koRBFyT9L+DLHuZm75J2obmy8Ce9rSz6QbkG5dk0R9pLaUZV9e20A+OldAkdwpNPIA/aXd8AKD0Hf94X/d51mjDogqRTgTcCi8pjGbApzbj6/WnuXjTb9q3Vioy+0HbrxxhwkjbqcJX+trb78m5nCYMuSdoQOIDmhOn2NPcAvgn4ju1f16yt18o8NMMalD+GkvYDPkvTL/5G4HSaO31tDBwzSHMTjUTS9bZfULuOXpH0cuALNB8YrwFmtSa57OcrkXMCuUvlYqoF5THoFtGcLBRNv3Dr/r9bAb8GplarrLc+SjNn1dNoRlEdafsnpc/432k+OAwESUcNtwrYrpe19IEP0UzXcoOk1wALJL3B9hX08cn0hEGMme2pAJI+A1zUupWfpENpLrQZFBu1ZqCUtKx1zsj2NeVGJoPkq8CX6DyiaNMe11LbxrZvALB9oaSbgG+U2X77tismYRB/iX1tn9R6Yvs7kj5Us6Aea79o851D1m3cy0L6wGLg32z/YugKSa+oUE9Nj0varnXCuBwhHAh8G9ilbmnDyxXIY1DOG8Qqv5H0LklTyuP/Ar+pXVQP/aukzQDa5+Apo8vOq1VUJW8FHhxm3at7WEc/mA1Mam8o8xLtT3Olel/KCeQxkHQb8HXgc4M4dfVQ5UTyacBLS9OPgPcMygnkiPVJwmAMJG1Oc0ObE2iOqubQ3NlruE9EsR4r50zO6nTnqjJn02uBR21/qefF9ZikdwFnD/dBQNIBwGaDcOMfSd+imZvqux2Glu5MM6HhHbbnVChvWAmDNSRpf+DLNCNoLqS5ynJJ1aJ6RNLHbL+1vOmf9Aay/aoKZfWcpD2AfwFeQDOdeev6k2nAFjQfFj7V6RaI6xtJRwD/TDPdwjWsvi/2AP4TeL/tZbVq7JVysdk/AX8LLGfVvpgC/Ar4D9sXVytwGAmDMSjnDA6nOTKYQjOW+EvAX9O80QdiMi5JL7a9qATik9j+Ya9rqknS04DptF1/YvuWulXVIWkaT74W50e2/1i1sEokTWHVvvhlP98jOmEwBuWcweU0s3L+dMi6s2z/Q53K6miFwpC23AM4Yh2UMBiDQbhhy1hIugY4vjWcUNJxwFtt71O3sogYq4RBFyT9OyNcLDJoRwQt5WTYhcDraLrKjgdeafuBqoVFxJjlorPuLKxdQD+yfZukY4Fv0kxDcfAg9g1LOtr210Zri8Ei6VTbHx+trV/kyKBL5eTxB22/vXYttUm6ntWPlJ5BM1f7owCDdue3TpOP9fOEZONJ0kTgJJoBFn/+sGn7jbVqqmWY98W1tl9Uq6aR5MigS7afKLNUBryydgH9oMzFdBiwg6Sz2lZtAaysU1V1FwM/phlK+kTlWqoo585eB0yVdEnbqs1phpr2pYTB2FxX/nG/Bvyh1Wj7G/VK6j3bd9auoU/8hmYG11eVry0PAf9YpaL6NrP9jtpFVPZT4B6a2+N+uK39IZo5nPpSuonGQNLnOjR7EA+BYxVJE2wP6pHAaiSdDvy0NZNtrDsSBhFrqMO5k9UM2rkTAEkPAU8FHisP0Xxg2qJqYT1U9kGn90Vf74uEwRhIejbNja4n2d5N0guBV9k+vXJpUYGkZ460Pt1psS5JGIyBpB8C/wf4dGtEgKRf2N6tbmUR/UGSgNcDU22/T9KOwPa2r6pcWs9J2qlTe7/eJjcnkMdmM9tXNe/3P0tf8YAb0i2wMbAR8Id+7Q4YZ2fT3BP6AOB9wH8DnwD2qllUJZe2LW9KczvYW4Dn1ylnZAmDsfltuXGJAcr9Te+pW1LUZnvz1nL5ZHwEsG+9iqrax/aekq4FsL1C0qDd9Q0A2y9of17ujX1ypXJGlTudjc0pwKeB50q6m+buTm+uWlH0FTe+CRxSu5ZKHi8XaLY+ME2kOVIYeLavAfp23q4cGYyB7duAV5Qbl2xg+6HaNUV9ko5qe7oBzXTWj1Qqp7azgIuASZLOAF4DvKtuSXVI+qe2pxsAe9LHt4VNGHRhyD9qezsAtj/S04Ki3/xN2/JK4A6arqKBY/tLkhYBB9IMpTzS9k2Vy6pl87bllTTnEL5eqZZRJQy60/pHfQ7NibDWJeZ/AwzcKIlYne0TatfQZ7YFHrb9OUkTJU21fXvtonrN9ntq1zAWGVo6BpJ+BBze6h4q90S+1PZLR35lrI8ytfmTSTqNppvsObafLemvgK/ZHph5vYa7HWxLv94WNkcGYzOJ5qrKlsdKWwym1tTm+wG7Al8tz48GbqxSUX2vBl5Ecx9kbP+mfGgaJP9Wvh4FbAd8sTw/DrivSkVdSBiMzXnAVZIuKs+PBD5frZqoyvZcAElvBl7Smp9I0qdoZu4cRI/ZtqTWaKKn1i6o11r3AJf0YdvT21Z9S1Lf3hslQ0vHwPYZwAnAivI4wfYH6lYVfWBrmmmrW55W2gbRBZI+DWwl6SSaqaw/W7mmWp5a7gYIgKSpNPM29aWcM+iCpG1GWm+7b+coj/En6QTg3cDlNCNoXgq8u3XkMGgkHQQcTLMv5tteULmkKiTNAM4BbqPZF88E3mR7ftXChpEw6IKk22lOCLXPQ9F6bts7d3xhDAxJ27HqgqIrbd9bs55aJH1w6P0MOrUNCkmbAM8tT2+2/WjNekaSMIhYCyRtDUyjmYMGANs/qldRHcPc6nHxIE7nDSBpN5rBBe3vi/PqVTS8nEAegw4zMu4EbDeIMzLGKpL+DjgVmAxcRzMv0c9oJmsbCOUk+snAzpLa7+a1OfBfdaqqqwyzfRlNGMwDDgV+QjMQpe/kyGAMJH2SMiOj7eeVT4Pfsz2IMzJGUW5ysxdwhe09JD0XeL/to0Z56XpD0pY0J80/AMxuW/XQoJ5TK++L3YFrbe8uaRLwRdsHVS6toxwZjE1mZIxOHrH9iCQkbWL7ZknPqV1UL9l+AHiAZix9NP5o+0+SVkraArgf2LF2UcNJGIxNZmSMTpZK2gr4JrBA0gogdzmLheV98RlgEc29HX5WtaIRpJtoDCS9HngtzeyDcykzMtr+WtXCom9I2h/YEviu7cdG2z4Gg6QpwBa2F4+2bS0JgzEq/cGtGRkvG+AZGSNiPZIwiIiITEcRERE5gRwRMS6GmcbmIduP97yYLqSbKCJiHEi6g2Yo6Qqac4xbAffSTGN9ku1F1YrrIN1EERHjYwFwmO1tbT+d5grkb9NcqX121co6yJFBRMQ4kHS97RcMaVts+4WSrrO9R6XSOso5g4iI8XGPpHcA55fnrwXuKxeu9t3FqjkyiIgYB5K2BU4DXlKa/gt4D820HTvZXlKrtk4SBhERkW6iiIjxIOnZwNuBKbT9rbXdl1Ob58ggImIcSPo58CmaSeqeaLX325DSloRBRMQ4kLTI9otr19GthEFExDiQ9G6aexhcBPz53sf9erOfhEFExDiQdHuHZtveuefFdCFhEBERGU0UETEeJB3fqd32eb2upRsJg4iI8bFX2/KmNDfFugboyzBIN1FERA+U+yGfb3tG7Vo6yaylERG98Qdgau0ihpNuooiIcSDpW0Cr62VD4HnABfUqGlm6iSIixoGk/duergTutL20Vj2jSTdRRMQ4sP1D4GZgc2Br4LG6FY0sYRARMQ4kHQNcBRwNHANcKek1dasaXrqJIiLGQZmo7iDb95fnE4H/tL173co6y5FBRMT42KAVBMXv6OO/uRlNFBExPr4raT7wlfL8tcC8ivWMKN1EERHjRNJRrLrt5Y9tX1SznpEkDCIixoGkvwe+aHtF7Vq60bf9VxER67hJwNWSLpA0Q5JqFzSSHBlERIyTEgAHAycA02muQD7X9q+qFtZBjgwiIsaJm0/b95bHSpqLzy6U9KGqhXWQI4OIiHEg6VTgeOC3wGeBb9p+XNIGwK22d6la4BAZWhoRMT62AY6yfWd7o+0/SXplpZqGlSODiIjIOYOIiEgYREQECYOIiCBhEBERJAwiIgL4/+jgR5F4Wj/EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_df['age'].value_counts().sort_values().plot(kind='bar')\n",
    "age_df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AFg_yQX5e8X"
   },
   "source": [
    "Since the distributions were rather skewed in all the shows, we had to mix and match data from the 3 corpora in order to obtain somewhat fair training and test datasets. Doing so helps prevent the classifier from learning biased predictions, because of certain labels occurring much more frequently in the training data. This opposed our original idea of using one or two datasets as training data and the others as test data to see if the trained model also worked on other corpora.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TFQRSZKcBPc"
   },
   "source": [
    "**Distribution rectification to be added**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TvRhTR2CrngF"
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "gen_model = LogisticRegression(n_jobs=4)\n",
    "age_model = LogisticRegression(n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0Ld24vw51-D"
   },
   "source": [
    "We selected a range of characters from the 3 datasets with specific gender and age labels. For the training dataset we sampled the dialogue equally across those with different gender and age labels. The test set consists of multiple dataframes with the residual dialogue of one specific character. This test set will be used to test the accuracy of the model, predicting labels for a specific character. We created two separate training and test sets for age and gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-5VwWwgHRat"
   },
   "source": [
    "Using the training datasets, the logistic regression models are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "w7FTtQgJrpGt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = train_test_split(gen_df['features'], gen_df['gender'], test_size=0.2)\n",
    "X_gen_train, X_gen_test, y_gen_train, y_gen_test = split\n",
    "\n",
    "X_gen_train = np.array(X_gen_train.values.tolist())\n",
    "y_gen_train = np.array(y_gen_train.values.tolist())\n",
    "\n",
    "gen_model.fit(X_gen_train, y_gen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rish6fr6rqZ2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = train_test_split(age_df['features'], age_df['age'], test_size=0.2)\n",
    "X_age_train, X_age_test, y_age_train, y_age_test = split\n",
    "\n",
    "X_age_train = np.array(X_age_train.values.tolist())\n",
    "y_age_train = np.array(y_age_train.values.tolist())\n",
    "\n",
    "age_model.fit(X_age_train, y_age_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnGQXBF76qjy"
   },
   "source": [
    "For personality predictions a biderectional LSTM with attention mechanisms is used. Code from the <a href='https://github.com/hjian42/automatic-personality-prediction'>Modeling Personality with Attentive Networks and Contextual Embeddings</a> is used and sligthly modified to train the model. The `train_persona` function trains the LSTM model using 10-fold cross-validation, from which the best performing model is stored, such that the model can be used later on. To reduce the complexity of the task, for each personality trait a seperate model is trained. Each model then learns to score a piece of conversation for a single personality trait. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "AmZ-7giFXB7h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of data is 711\n",
      "BEFORE Pruning:\n",
      "Min=2, Mean=56, Max=443\n",
      "Total majority is 56.962025316455694 for cAGR.\n",
      "Real Vocab Size: 3542\n",
      "Truncated Vocab Size: 10000\n",
      "AFTER Pruning:\n",
      "Min=1, Mean=29, Max=218\n",
      "Total majority is 56.962025316455694 for cAGR.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56944, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56944\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.56944 to 0.62500, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.62500\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.62500 to 0.63889, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.63889\n",
      "working on ==cAGR==\n",
      "----cAGR: 1----\n",
      "----highest evaluation accuracy is 63.888890\n",
      "----dominant distribution in data is 56.962025\n",
      "New best evaluation, saving model to models/cAGR_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.59155 to 0.61972, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.61972 to 0.63380, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.63380 to 0.66197, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.66197 to 0.67606, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.67606\n",
      "working on ==cAGR==\n",
      "----cAGR: 2----\n",
      "----highest evaluation accuracy is 67.605633\n",
      "----dominant distribution in data is 56.962025\n",
      "New best evaluation, saving model to models/cAGR_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.56338 to 0.59155, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cAGR==\n",
      "----cAGR: 3----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 56.962025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.56338 to 0.59155, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cAGR==\n",
      "----cAGR: 4----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 56.962025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.56338 to 0.66197, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.66197 to 0.69014, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.69014\n",
      "working on ==cAGR==\n",
      "----cAGR: 5----\n",
      "----highest evaluation accuracy is 69.014084\n",
      "----dominant distribution in data is 56.962025\n",
      "New best evaluation, saving model to models/cAGR_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.56338 to 0.59155, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.59155 to 0.60563, saving model to models/cAGR_cur.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_accuracy improved from 0.60563 to 0.64789, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.64789\n",
      "working on ==cAGR==\n",
      "----cAGR: 6----\n",
      "----highest evaluation accuracy is 64.788735\n",
      "----dominant distribution in data is 56.962025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57746, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.57746 to 0.61972, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.61972\n",
      "working on ==cAGR==\n",
      "----cAGR: 7----\n",
      "----highest evaluation accuracy is 61.971831\n",
      "----dominant distribution in data is 56.962025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57746, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.57746 to 0.61972, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.61972\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.61972 to 0.66197, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.66197 to 0.69014, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.69014 to 0.70423, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.70423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.70423\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.70423\n",
      "working on ==cAGR==\n",
      "----cAGR: 8----\n",
      "----highest evaluation accuracy is 70.422536\n",
      "----dominant distribution in data is 56.962025\n",
      "New best evaluation, saving model to models/cAGR_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57746, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.59155 to 0.60563, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.60563\n",
      "working on ==cAGR==\n",
      "----cAGR: 9----\n",
      "----highest evaluation accuracy is 60.563380\n",
      "----dominant distribution in data is 56.962025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57746, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cAGR_cur.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cAGR==\n",
      "----cAGR: 10----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 56.962025\n",
      "The 10-fold CV score is 0.6357198715209961\n",
      "The size of data is 711\n",
      "BEFORE Pruning:\n",
      "Min=2, Mean=56, Max=443\n",
      "Total majority is 53.586497890295355 for cCON.\n",
      "Real Vocab Size: 3542\n",
      "Truncated Vocab Size: 10000\n",
      "AFTER Pruning:\n",
      "Min=1, Mean=29, Max=218\n",
      "Total majority is 53.586497890295355 for cCON.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54167, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.54167\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.54167 to 0.55556, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.55556 to 0.58333, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.58333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.58333\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.58333\n",
      "working on ==cCON==\n",
      "----cCON: 1----\n",
      "----highest evaluation accuracy is 58.333331\n",
      "----dominant distribution in data is 53.586498\n",
      "New best evaluation, saving model to models/cCON_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cCON==\n",
      "----cCON: 2----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.53521 to 0.59155, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.59155 to 0.64789, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.64789 to 0.67606, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.67606\n",
      "working on ==cCON==\n",
      "----cCON: 3----\n",
      "----highest evaluation accuracy is 67.605633\n",
      "----dominant distribution in data is 53.586498\n",
      "New best evaluation, saving model to models/cCON_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cCON==\n",
      "----cCON: 4----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cCON==\n",
      "----cCON: 5----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.53521 to 0.56338, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.56338 to 0.59155, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cCON==\n",
      "----cCON: 6----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cCON==\n",
      "----cCON: 7----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.54930\n",
      "working on ==cCON==\n",
      "----cCON: 8----\n",
      "----highest evaluation accuracy is 54.929578\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.54930\n",
      "working on ==cCON==\n",
      "----cCON: 9----\n",
      "----highest evaluation accuracy is 54.929578\n",
      "----dominant distribution in data is 53.586498\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.54930 to 0.57746, saving model to models/cCON_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.57746\n",
      "working on ==cCON==\n",
      "----cCON: 10----\n",
      "----highest evaluation accuracy is 57.746476\n",
      "----dominant distribution in data is 53.586498\n",
      "The 10-fold CV score is 0.5667840301990509\n",
      "The size of data is 711\n",
      "BEFORE Pruning:\n",
      "Min=2, Mean=56, Max=443\n",
      "Total majority is 56.118143459915615 for cEXT.\n",
      "Real Vocab Size: 3542\n",
      "Truncated Vocab Size: 10000\n",
      "AFTER Pruning:\n",
      "Min=1, Mean=29, Max=218\n",
      "Total majority is 56.118143459915615 for cEXT.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55556, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.55556 to 0.58333, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.58333 to 0.59722, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59722\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59722\n",
      "working on ==cEXT==\n",
      "----cEXT: 1----\n",
      "----highest evaluation accuracy is 59.722221\n",
      "----dominant distribution in data is 56.118143\n",
      "New best evaluation, saving model to models/cEXT_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54930, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.54930 to 0.56338, saving model to models/cEXT_cur.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cEXT==\n",
      "----cEXT: 2----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cEXT==\n",
      "----cEXT: 3----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.57746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.57746\n",
      "working on ==cEXT==\n",
      "----cEXT: 4----\n",
      "----highest evaluation accuracy is 57.746476\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cEXT==\n",
      "----cEXT: 5----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.59155 to 0.60563, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.60563\n",
      "working on ==cEXT==\n",
      "----cEXT: 6----\n",
      "----highest evaluation accuracy is 60.563380\n",
      "----dominant distribution in data is 56.118143\n",
      "New best evaluation, saving model to models/cEXT_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.56338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.56338\n",
      "working on ==cEXT==\n",
      "----cEXT: 7----\n",
      "----highest evaluation accuracy is 56.338030\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.56338\n",
      "working on ==cEXT==\n",
      "----cEXT: 8----\n",
      "----highest evaluation accuracy is 56.338030\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.56338\n",
      "working on ==cEXT==\n",
      "----cEXT: 9----\n",
      "----highest evaluation accuracy is 56.338030\n",
      "----dominant distribution in data is 56.118143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56338, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.57746 to 0.59155, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.59155 to 0.60563, saving model to models/cEXT_cur.h5\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.60563\n",
      "working on ==cEXT==\n",
      "----cEXT: 10----\n",
      "----highest evaluation accuracy is 60.563380\n",
      "----dominant distribution in data is 56.118143\n",
      "The 10-fold CV score is 0.5850743293762207\n",
      "The size of data is 711\n",
      "BEFORE Pruning:\n",
      "Min=2, Mean=56, Max=443\n",
      "Total majority is 64.9789029535865 for cOPN.\n",
      "Real Vocab Size: 3542\n",
      "Truncated Vocab Size: 10000\n",
      "AFTER Pruning:\n",
      "Min=1, Mean=29, Max=218\n",
      "Total majority is 64.9789029535865 for cOPN.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65278, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.65278\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.65278\n",
      "working on ==cOPN==\n",
      "----cOPN: 1----\n",
      "----highest evaluation accuracy is 65.277779\n",
      "----dominant distribution in data is 64.978903\n",
      "New best evaluation, saving model to models/cOPN_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66197, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66197 to 0.69014, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.69014\n",
      "working on ==cOPN==\n",
      "----cOPN: 2----\n",
      "----highest evaluation accuracy is 69.014084\n",
      "----dominant distribution in data is 64.978903\n",
      "New best evaluation, saving model to models/cOPN_best.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.64789\n",
      "working on ==cOPN==\n",
      "----cOPN: 3----\n",
      "----highest evaluation accuracy is 64.788735\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.64789\n",
      "working on ==cOPN==\n",
      "----cOPN: 4----\n",
      "----highest evaluation accuracy is 64.788735\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.64789 to 0.66197, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.66197\n",
      "working on ==cOPN==\n",
      "----cOPN: 5----\n",
      "----highest evaluation accuracy is 66.197181\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.64789 to 0.66197, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.66197\n",
      "working on ==cOPN==\n",
      "----cOPN: 6----\n",
      "----highest evaluation accuracy is 66.197181\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.64789\n",
      "working on ==cOPN==\n",
      "----cOPN: 7----\n",
      "----highest evaluation accuracy is 64.788735\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.64789 to 0.66197, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.66197 to 0.67606, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67606 to 0.69014, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.69014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.69014\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.69014\n",
      "working on ==cOPN==\n",
      "----cOPN: 8----\n",
      "----highest evaluation accuracy is 69.014084\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.64789\n",
      "working on ==cOPN==\n",
      "----cOPN: 9----\n",
      "----highest evaluation accuracy is 64.788735\n",
      "----dominant distribution in data is 64.978903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64789, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64789\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.64789 to 0.66197, saving model to models/cOPN_cur.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.66197\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.66197\n",
      "working on ==cOPN==\n",
      "----cOPN: 10----\n",
      "----highest evaluation accuracy is 66.197181\n",
      "----dominant distribution in data is 64.978903\n",
      "The 10-fold CV score is 0.6610524296760559\n",
      "The size of data is 711\n",
      "BEFORE Pruning:\n",
      "Min=2, Mean=56, Max=443\n",
      "Total majority is 53.30520393811533 for cNEU.\n",
      "Real Vocab Size: 3542\n",
      "Truncated Vocab Size: 10000\n",
      "AFTER Pruning:\n",
      "Min=1, Mean=29, Max=218\n",
      "Total majority is 53.30520393811533 for cNEU.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52778, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.52778\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.52778\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.52778\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.52778\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.52778\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.52778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.52778\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.52778 to 0.62500, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.62500 to 0.63889, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.63889\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.63889\n",
      "working on ==cNEU==\n",
      "----cNEU: 1----\n",
      "----highest evaluation accuracy is 63.888890\n",
      "----dominant distribution in data is 53.305204\n",
      "New best evaluation, saving model to models/cNEU_best.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52113, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.52113\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.52113 to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cNEU==\n",
      "----cNEU: 2----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.54930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.54930\n",
      "working on ==cNEU==\n",
      "----cNEU: 3----\n",
      "----highest evaluation accuracy is 54.929578\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.54930 to 0.56338, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.57746\n",
      "working on ==cNEU==\n",
      "----cNEU: 4----\n",
      "----highest evaluation accuracy is 57.746476\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.54930 to 0.56338, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.56338\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.56338 to 0.57746, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.57746\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.57746\n",
      "working on ==cNEU==\n",
      "----cNEU: 5----\n",
      "----highest evaluation accuracy is 57.746476\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cNEU==\n",
      "----cNEU: 6----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.53521 to 0.59155, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59155\n",
      "working on ==cNEU==\n",
      "----cNEU: 7----\n",
      "----highest evaluation accuracy is 59.154928\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.54930\n",
      "working on ==cNEU==\n",
      "----cNEU: 8----\n",
      "----highest evaluation accuracy is 54.929578\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.53521 to 0.54930, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.54930\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.54930 to 0.56338, saving model to models/cNEU_cur.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_accuracy improved from 0.56338 to 0.59155, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59155\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.59155 to 0.60563, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.60563\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.60563 to 0.61972, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.61972 to 0.63380, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.63380\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.63380\n",
      "working on ==cNEU==\n",
      "----cNEU: 9----\n",
      "----highest evaluation accuracy is 63.380283\n",
      "----dominant distribution in data is 53.305204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53521, saving model to models/cNEU_cur.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.53521\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.53521\n",
      "working on ==cNEU==\n",
      "----cNEU: 10----\n",
      "----highest evaluation accuracy is 53.521127\n",
      "----dominant distribution in data is 53.305204\n",
      "The 10-fold CV score is 0.5723395884037018\n"
     ]
    }
   ],
   "source": [
    "config.ModelName = 'Attention'\n",
    "config.Params.n_epoch = 50\n",
    "\n",
    "train_persona(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e8fq20-YpYz"
   },
   "source": [
    "## Evaluation\n",
    "To evaluate the trained gender and age prediction model, we run the test dataset with its corresponding labels through the scikit Logistic Regression *score* function. The *score* function computes the mean accuracy of the given input, by running every data row of the test set through the scikit Logistic Regression *predict* function and comparing the predicted label with the actual label. Hence, the mean accuracy represents the percentage of correctly predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wfiK6Fwnamlj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7052210990845932"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gen_test = np.array(X_gen_test.values.tolist())\n",
    "y_gen_test = np.array(y_gen_test.values.tolist())\n",
    "\n",
    "gen_model.score(X_gen_test, y_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "l4lTAqcMrvNR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726022859035945"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_age_test = np.array(X_age_test.values.tolist())\n",
    "y_age_test = np.array(y_age_test.values.tolist())\n",
    "\n",
    "age_model.score(X_age_test, y_age_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTpXhK4g7ZUw"
   },
   "source": [
    "\n",
    "Thus now the models are able to predict or classify a gender and age label, given a dialogue line with an about 70% accuracy. However, we want to predict the gender and age of a character given all his/her dialogue lines. To do so, we simply let the model predict labels for each line of a specific character and take the most frequent label as final prediction. The dialogue lines also go through the get_bert_features() function in order to become a suitable format for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdDyDqeGaoXr"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CAyLjwmSatgi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted Male for Ross Geller, actual: Male\n",
      " dialogue: Mmm hmmm.\n"
     ]
    }
   ],
   "source": [
    "gen_sample_row = gen_df.sample().values[0]\n",
    "y_hat = gen_model.predict([gen_sample_row[-1].tolist()])[0]\n",
    "print(f'predicted {y_hat} for {gen_sample_row[1]}, actual: {gen_sample_row[4]}\\n dialogue: {gen_sample_row[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AxnFMOqnryId"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted teen (10-19) for JULIE, actual: young adult (20-35)\n",
      " dialogue: What's the maximum safe dose?\n"
     ]
    }
   ],
   "source": [
    "age_sample_row = age_df.sample().values[0]\n",
    "y_hat = age_model.predict([age_sample_row[-1].tolist()])[0]\n",
    "print(f'predicted {y_hat} for {age_sample_row[1]}, actual: {age_sample_row[3]}\\n dialogue: {age_sample_row[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7e06VY4aybd"
   },
   "source": [
    "**TODO: Personalities results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZvV3UlEbBjI"
   },
   "source": [
    "## Findings\n",
    "The reasonable results suggest that it is possible to predict the selected profile features given the dialogue of a person/character. It can even be said that it is possible to predict is quite well. However, the predictions aren't always perfect as we haven't acquired a +/- 100% accuracy. <br>\n",
    "The results also indicate that the models are better at predicting gender than age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvBtf1SsbjFM"
   },
   "source": [
    "### Discussion\n",
    "1. Accuracy may be influenced by the mildly skewed data\n",
    "2. Some of the data may have not been representative for the general age group. South Park, for example stars 5 young teenagers who use language that is usually not representative for ten year olds. In movies, fictional characters talk about things and experience things that are very unusual in other movies. For representative results for age groups, similar movies/tv-shows or general conversations need to be used. (to be elaborated)\n",
    "3. The personality dataset contained just around 800 data points to train on. There was also only data available for the five Friends main characters, so an absolute judgement of how well it performs cannot be made. All Friends main characters have similar character traits, so for a more in-depth research, more  \n",
    "4. A default LR model is only meant for prediction between 2 classes, instead of multi-classifications like age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypbqtTgbbvC9"
   },
   "source": [
    "## Conclusions\n",
    "In this final section we will briefly summarize the research we have conducted during this project and explain our findings. Then, we will elaborate on the lessons we have learned, and finally we will provide some suggestions of future work\n",
    "\n",
    "### Summary\n",
    "During this project we investigated if and to what extent dialogue could be used to predict profile features including gender, age and personality of a person, represented by movie and tv-show characters. The first part of the project consisted of cleaning and processing the datasets and analysing the contents and metadata. After having created a fairer training dataset, we could give the input to the models. For predicting gender and age we used a combination of the DistilBERT- and the Logistic Regression model. For predicting personality we have used a bi-directional LSTM. We evaluated the models based on the accuracy of their predictions. Furthermore, we elaborated the use of the models to predict the profile features of a character, based on all of their dialogue lines.\n",
    "\n",
    "### Lessons learned\n",
    "Possibly biased data and therefore predictions are a well-known problem in the field of artificial intelligence and machine learning. Doing this project we faced and realized the significance of this issue and the importance of trying to get a fair training dataset in order to get fair results. Although the task we achieved is relatively small and simple, it showed us that natural language processing can indeed be used in many different tasks and fields. We did realize however that the nature of the models restricts the transparency and explainability of the results. For example, we don’t know what features correspond more strongly to specific genders, age categories and personalities. Although the results are therefore not useful in knowing certain characteristics of speech, the predictions can still come in handy for when you want to have an estimation of someone’s profile features. Nevertheless, an analysis of profile features distinguishing features was outside the scope of this project and another project on its own.\n",
    "\n",
    "This project also allowed us to take a look at state-of-the-art models and actually try them out, giving us more insight into the field of NLP. \n",
    "\n",
    "Lastly, naturally with a team project, we developed collaborating skills. This was especially essential during the current times of the pandemic, which forced us to keep each other updated and communicate planning and tasks.\n",
    "\n",
    "### Future work\n",
    "Even though the results of the project were interesting and promising, there is still a lot that could be improved. To e.g. increase the accuracy of the models, it might be useful to create a better and fairer training dataset. Although we did try to fairly sample all the datasets, within the scope of the project and the time we had, it wasn’t perfect. It might be promising to instead of using movie and tv-series as data, to use real-life transcripts of interviews, dialogues or chats, etc. This could be achieved by setting up an experiment and gather participants with a fair spread of desired profile features. Moreover, it could be insightful to try out different classification models and compare results and accuracy. When we want to predict a feature that can have multiple labels, it can be more suitable to use a classifier specialized in more classes, such as a multilayer perceptron or a multinomial bayes classifier. The research could also be extended to predicting other interesting profile features, such as education level or profession.\n",
    "\n",
    "When a more accurate profile feature predictor can be built, it could be fruitful in usage for a chatbot. If a chatbot is able to guess characteristics of its conversation partner, then its conversational style and language usage could be adjusted accordingly, in order to make for smoother and more successful conversations. And if the chatbot is asked for e.g. movie recommendations, then it will perhaps be able to recommend more suitable movies."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final Project Structured.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lsdp",
   "language": "python",
   "name": "lsdp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
